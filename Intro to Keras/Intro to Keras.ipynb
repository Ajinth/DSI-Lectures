{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people, load_breast_cancer, load_iris\n",
    "people = fetch_lfw_people(min_faces_per_person=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "X_train.shape # shows how many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(13, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/20\n",
      "379/379 [==============================] - 0s 48us/step - loss: 17.6612 - val_loss: 24.7176\n",
      "Epoch 2/20\n",
      "379/379 [==============================] - 0s 45us/step - loss: 17.5652 - val_loss: 24.6105\n",
      "Epoch 3/20\n",
      "379/379 [==============================] - 0s 48us/step - loss: 17.4400 - val_loss: 24.6698\n",
      "Epoch 4/20\n",
      "379/379 [==============================] - 0s 45us/step - loss: 17.2978 - val_loss: 24.4757\n",
      "Epoch 5/20\n",
      "379/379 [==============================] - 0s 48us/step - loss: 17.1658 - val_loss: 24.2497\n",
      "Epoch 6/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 17.0609 - val_loss: 24.2217\n",
      "Epoch 7/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.9284 - val_loss: 24.0070\n",
      "Epoch 8/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.8308 - val_loss: 23.8259\n",
      "Epoch 9/20\n",
      "379/379 [==============================] - 0s 45us/step - loss: 16.7377 - val_loss: 23.7528\n",
      "Epoch 10/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.6251 - val_loss: 23.5382\n",
      "Epoch 11/20\n",
      "379/379 [==============================] - 0s 40us/step - loss: 16.5656 - val_loss: 23.7527\n",
      "Epoch 12/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.3844 - val_loss: 23.4867\n",
      "Epoch 13/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.3134 - val_loss: 23.1868\n",
      "Epoch 14/20\n",
      "379/379 [==============================] - 0s 45us/step - loss: 16.2107 - val_loss: 23.1690\n",
      "Epoch 15/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 16.0895 - val_loss: 23.2110\n",
      "Epoch 16/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 15.9768 - val_loss: 23.0433\n",
      "Epoch 17/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 15.8760 - val_loss: 22.9298\n",
      "Epoch 18/20\n",
      "379/379 [==============================] - 0s 45us/step - loss: 15.8018 - val_loss: 22.7768\n",
      "Epoch 19/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 15.7115 - val_loss: 22.8368\n",
      "Epoch 20/20\n",
      "379/379 [==============================] - 0s 42us/step - loss: 15.6222 - val_loss: 22.7436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2049af99c50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.target * -1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, target)\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/10\n",
      "426/426 [==============================] - 1s 1ms/step - loss: 0.8639 - acc: 0.4319 - val_loss: 0.7304 - val_acc: 0.5105\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.5658 - acc: 0.6690 - val_loss: 0.5040 - val_acc: 0.7273\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.3980 - acc: 0.8474 - val_loss: 0.3669 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.3015 - acc: 0.9225 - val_loss: 0.2864 - val_acc: 0.9161\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.2448 - acc: 0.9437 - val_loss: 0.2365 - val_acc: 0.9301\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 0s 56us/step - loss: 0.2084 - acc: 0.9460 - val_loss: 0.2034 - val_acc: 0.9441\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.1824 - acc: 0.9460 - val_loss: 0.1809 - val_acc: 0.9510\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 0s 47us/step - loss: 0.1632 - acc: 0.9507 - val_loss: 0.1630 - val_acc: 0.9510\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.1480 - acc: 0.9624 - val_loss: 0.1495 - val_acc: 0.9650\n",
      "Epoch 10/10\n",
      "426/426 [==============================] - 0s 52us/step - loss: 0.1353 - acc: 0.9648 - val_loss: 0.1388 - val_acc: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2049e051dd8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02562111],\n",
       "       [ 0.99456537],\n",
       "       [ 0.99950421],\n",
       "       [ 0.58101761],\n",
       "       [ 0.12250246],\n",
       "       [ 0.07875784],\n",
       "       [ 0.34652734],\n",
       "       [ 0.99992824],\n",
       "       [ 0.99377811],\n",
       "       [ 0.00602841],\n",
       "       [ 0.99233961],\n",
       "       [ 0.03063892],\n",
       "       [ 0.10232757],\n",
       "       [ 0.2472126 ],\n",
       "       [ 0.08395835],\n",
       "       [ 0.06561336],\n",
       "       [ 0.99999332],\n",
       "       [ 0.99940383],\n",
       "       [ 0.02966477],\n",
       "       [ 0.09148387],\n",
       "       [ 0.93057573],\n",
       "       [ 0.02453707],\n",
       "       [ 0.11719768],\n",
       "       [ 0.08402832],\n",
       "       [ 0.0878014 ],\n",
       "       [ 0.99969876],\n",
       "       [ 0.98739803],\n",
       "       [ 1.        ],\n",
       "       [ 0.13559192],\n",
       "       [ 0.05173052],\n",
       "       [ 0.99987435],\n",
       "       [ 0.06505246],\n",
       "       [ 0.03045276],\n",
       "       [ 0.8742128 ],\n",
       "       [ 0.0149174 ],\n",
       "       [ 0.15162793],\n",
       "       [ 0.00514573],\n",
       "       [ 0.07250049],\n",
       "       [ 0.99993587],\n",
       "       [ 0.06274789],\n",
       "       [ 0.05601579],\n",
       "       [ 0.06322663],\n",
       "       [ 0.14306934],\n",
       "       [ 0.04808632],\n",
       "       [ 0.98365849],\n",
       "       [ 0.9377864 ],\n",
       "       [ 0.07729083],\n",
       "       [ 0.08272371],\n",
       "       [ 0.00581814],\n",
       "       [ 0.99948931],\n",
       "       [ 0.15768108],\n",
       "       [ 0.15866724],\n",
       "       [ 0.012472  ],\n",
       "       [ 0.04366458],\n",
       "       [ 0.91536969],\n",
       "       [ 0.01412478],\n",
       "       [ 0.99873525],\n",
       "       [ 0.34685621],\n",
       "       [ 0.01571743],\n",
       "       [ 0.00605887],\n",
       "       [ 0.11937524],\n",
       "       [ 0.93065524],\n",
       "       [ 0.9999851 ],\n",
       "       [ 0.99527031],\n",
       "       [ 0.89803898],\n",
       "       [ 0.94339776],\n",
       "       [ 0.0291364 ],\n",
       "       [ 0.1859224 ],\n",
       "       [ 0.93197364],\n",
       "       [ 0.02608866],\n",
       "       [ 0.31224701],\n",
       "       [ 0.23148382],\n",
       "       [ 0.06512514],\n",
       "       [ 0.04184747],\n",
       "       [ 0.95725077],\n",
       "       [ 0.02209481],\n",
       "       [ 0.03498279],\n",
       "       [ 0.091506  ],\n",
       "       [ 0.53628343],\n",
       "       [ 0.45292357],\n",
       "       [ 0.07184817],\n",
       "       [ 0.80815136],\n",
       "       [ 0.09805243],\n",
       "       [ 0.07864141],\n",
       "       [ 0.99940431],\n",
       "       [ 0.0290202 ],\n",
       "       [ 0.06701324],\n",
       "       [ 0.99420089],\n",
       "       [ 0.97285819],\n",
       "       [ 0.37082529],\n",
       "       [ 0.78498274],\n",
       "       [ 0.9664169 ],\n",
       "       [ 0.10350953],\n",
       "       [ 0.04559763],\n",
       "       [ 0.0139951 ],\n",
       "       [ 0.07702392],\n",
       "       [ 0.00522835],\n",
       "       [ 0.92298925],\n",
       "       [ 0.46077502],\n",
       "       [ 0.08250748],\n",
       "       [ 0.64231008],\n",
       "       [ 0.05006221],\n",
       "       [ 0.36942789],\n",
       "       [ 0.45299819],\n",
       "       [ 0.04398404],\n",
       "       [ 0.87717587],\n",
       "       [ 0.13169764],\n",
       "       [ 0.12481597],\n",
       "       [ 0.99969804],\n",
       "       [ 0.0489689 ],\n",
       "       [ 0.00840702],\n",
       "       [ 0.08103097],\n",
       "       [ 0.01146976],\n",
       "       [ 0.04663303],\n",
       "       [ 0.19415504],\n",
       "       [ 0.10845558],\n",
       "       [ 0.03976464],\n",
       "       [ 0.10545832],\n",
       "       [ 0.89407855],\n",
       "       [ 0.02600169],\n",
       "       [ 0.0458592 ],\n",
       "       [ 0.46815452],\n",
       "       [ 0.99899918],\n",
       "       [ 0.11832002],\n",
       "       [ 0.05849018],\n",
       "       [ 0.04416529],\n",
       "       [ 0.04568558],\n",
       "       [ 0.62044829],\n",
       "       [ 0.03981424],\n",
       "       [ 0.0129315 ],\n",
       "       [ 0.222311  ],\n",
       "       [ 0.31514227],\n",
       "       [ 0.00967134],\n",
       "       [ 0.01030382],\n",
       "       [ 0.95672208],\n",
       "       [ 0.07609427],\n",
       "       [ 0.05542484],\n",
       "       [ 0.00939813],\n",
       "       [ 0.03129892],\n",
       "       [ 0.01203269],\n",
       "       [ 0.80809313],\n",
       "       [ 0.16603771],\n",
       "       [ 0.00973996]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 42us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "pred[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train= ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 1.3104 - acc: 0.3571 - val_loss: 1.2300 - val_acc: 0.2632\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.4100 - acc: 0.2857 - val_loss: 1.2194 - val_acc: 0.2632\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.3886 - acc: 0.3125 - val_loss: 1.2093 - val_acc: 0.2632\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2924 - acc: 0.2589 - val_loss: 1.1998 - val_acc: 0.2632\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.3369 - acc: 0.3393 - val_loss: 1.1907 - val_acc: 0.2895\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2961 - acc: 0.3393 - val_loss: 1.1814 - val_acc: 0.2895\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.2119 - acc: 0.3482 - val_loss: 1.1721 - val_acc: 0.2895\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 45us/step - loss: 1.1614 - acc: 0.3393 - val_loss: 1.1631 - val_acc: 0.2895\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 45us/step - loss: 1.2525 - acc: 0.3482 - val_loss: 1.1540 - val_acc: 0.2895\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.2183 - acc: 0.4196 - val_loss: 1.1452 - val_acc: 0.2895\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2453 - acc: 0.3125 - val_loss: 1.1368 - val_acc: 0.2895\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.1803 - acc: 0.3839 - val_loss: 1.1287 - val_acc: 0.2632\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2339 - acc: 0.2946 - val_loss: 1.1213 - val_acc: 0.2632\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2028 - acc: 0.3214 - val_loss: 1.1138 - val_acc: 0.2632\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.1852 - acc: 0.3482 - val_loss: 1.1063 - val_acc: 0.2895\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.1466 - acc: 0.3036 - val_loss: 1.0986 - val_acc: 0.2895\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.2630 - acc: 0.2857 - val_loss: 1.0910 - val_acc: 0.2895\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 63us/step - loss: 1.1497 - acc: 0.3750 - val_loss: 1.0837 - val_acc: 0.2895\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 54us/step - loss: 1.1340 - acc: 0.3036 - val_loss: 1.0767 - val_acc: 0.2895\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 45us/step - loss: 1.1394 - acc: 0.4464 - val_loss: 1.0704 - val_acc: 0.3421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2049d6f2780>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(.5, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_lfw_people(min_faces_per_person=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x204a453b278>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMoAAAD8CAYAAAA2RjsYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw5EBHygORwb+P9uwRFnyClY8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204a4326d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "       'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'],\n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 3, ..., 5, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  77.33333588,   80.        ,  112.33333588, ...,   43.33333206,\n",
       "         41.33333206,   52.        ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 966 samples, validate on 322 samples\n",
      "Epoch 1/5\n",
      "966/966 [==============================] - 2s 2ms/step - loss: 8.6271 - acc: 0.3799 - val_loss: 10.0112 - val_acc: 0.3789\n",
      "Epoch 2/5\n",
      "966/966 [==============================] - 2s 2ms/step - loss: 9.3105 - acc: 0.4224 - val_loss: 10.0112 - val_acc: 0.3789\n",
      "Epoch 3/5\n",
      "966/966 [==============================] - 2s 2ms/step - loss: 9.3105 - acc: 0.4224 - val_loss: 10.0112 - val_acc: 0.3789\n",
      "Epoch 4/5\n",
      "966/966 [==============================] - 2s 2ms/step - loss: 9.3105 - acc: 0.4224 - val_loss: 10.0112 - val_acc: 0.3789\n",
      "Epoch 5/5\n",
      "966/966 [==============================] - 2s 2ms/step - loss: 9.3105 - acc: 0.4224 - val_loss: 10.0112 - val_acc: 0.3789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204a48650b8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
