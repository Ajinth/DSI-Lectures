{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords\n",
    "import wikipedia\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Review Lab (50 Minutes)\n",
    "\n",
    "There are a lot of moving pieces in NLP and it is worthwhile to keep practicing the techniques we started to acquire yesterday. \n",
    "\n",
    "The first section of our lesson today will be a chance to review those topics and to practice discussing NLP and machine learning together. \n",
    "\n",
    "We'll be using a truncated version of the [Amazon Fine Food Review](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) dataset. For a larger project, we would make use of the full set of data. However, in the interest of processing time, we'll use a randomly sampled set of 10,000 reviews for our training set and an additional 2,000 reviews for our test set.\n",
    "\n",
    "Your goal will be to create a predictive model that classifies a review into a high scoring review (5 stars) or not a high scoring review (1-4 stars). This value is already present in the data under the name `high_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/amazon_train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['Text']\n",
    "y = train['high_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop = stopwords.words('english')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.lower().strip()\n",
    "    final_text = []\n",
    "    for w in text.split():\n",
    "        if w not in stop:\n",
    "            final_text.append(stemmer.stem(w.strip()))\n",
    "    return ' '.join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(preprocessor=cleaner)\n",
    "Xtrain_cv = cv.fit_transform(X_train)\n",
    "Xtrain_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=500)\n",
    "Xtrain_tsvd = tsvd.fit_transform(Xtrain_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(3000), tsvd.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "params = {'penalty':['l1','l2'],\n",
    "         'C':[0.01,0.50,0.75]}\n",
    "\n",
    "gs = GridSearchCV(lg, param_grid=params, scoring='recall', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(Xtrain_tsvd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsb = gs.best_estimator_\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_cv = cv.fit_transform(X_test)\n",
    "Xtest_tsvd = tsvd.fit_transform(Xtest_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsb.score(Xtest_tsvd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lg__penalty':['l1','l2'],\n",
    "         'lg__C':[0.25,0.5,0.75,10]}\n",
    "\n",
    "lg_pipe = Pipeline([('cv', CountVectorizer(stop_words='english', min_df=0.01)),\n",
    "                    ('tsvd', TruncatedSVD(n_components=500)),\n",
    "                   ('lg', LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(lg_pipe, param_grid=params, scoring='recall', n_jobs=-1, verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsb = gs.best_estimator_\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsb.score(X_train, y_train))\n",
    "print(gsb.score(X_test, y_test))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, gsb.predict(X_test)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, gsb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(preprocessor=cleaner)\n",
    "\n",
    "X_cv = cv.fit_transform(X_train)\n",
    "\n",
    "X_cv.shape\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "X_tsvd = tsvd.fit_transform(X_cv)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_tsvd, y_train)\n",
    "print('rfc score:', rfc.score(X_tsvd, y_train))\n",
    "print('confusion matrix:' , confusion_matrix(y_train, rfc.predict(X_tsvd)))\n",
    "print('classification report:', classification_report(y_train, rfc.predict(X_tsvd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid= {'C': [0.01,.10, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2']}\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), param_grid=param_grid, scoring='recall', n_jobs=-1, verbose=2)\n",
    "gs.fit(X_tsvd, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('gs best params:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('gs best score:', gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_cv = cv.transform(X_test)\n",
    "X_test_svd = tsvd.transform(X_test_cv)\n",
    "# print('rfc score:', rfc.score(X_test_svd, y_test))\n",
    "# print('confusion matrix:', confusion_matrix(y_test, rfc.predict(X_test_svd)))\n",
    "# print('classifcation report:', classification_report(y_test, rfc.predict(X_test_svd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('gs best estimatoor:', best_estimator.score(X_test_svd, y_test))\n",
    "print('confusion matrix:', confusion_matrix(y_test, gs.predict(X_test_svd)))\n",
    "print('classifcation report:', classification_report(y_test, gs.predict(X_test_svd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajinth's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the Targets and Features '''\n",
    "X = train['Text']\n",
    "y = train['high_score']\n",
    "\n",
    "Xn = test['Text']\n",
    "yn =test['high_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)\n",
    "\n",
    "\n",
    "'''Setting up the TFIDVectorizer'''\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "'''Intantiating Logreg'''\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "'''Setting up the Parameters for GridSearch'''\n",
    "params = {\n",
    "\n",
    "    'logreg__penalty': ['l1', 'l2'], \n",
    "    'logreg__C': [1.0,10,100], \n",
    "    'logreg__max_iter': [100,150,200]   \n",
    "}\n",
    "\n",
    "'''Setting the Pipeline'''\n",
    "logreg_tk_pipe = Pipeline([('vect', tf), \n",
    "                     ('logreg', logreg)])\n",
    "\n",
    "'''Fitting the Model on Training'''\n",
    "gs_logreg = GridSearchCV(logreg_tk_pipe, param_grid=params,n_jobs = -1, verbose=2, scoring='accuracy')\n",
    "gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print ('Best Params: ' , gs_logreg.best_params_) \n",
    "print ('Best Score: ', gs_logreg.best_score_)\n",
    "print ('Train-Train Score: ',gs_logreg.score(X_train, y_train))\n",
    "print ('Train-Test Score: ', gs_logreg.score(X_test, y_test))\n",
    "print ('Real Test Score: ', gs_logreg.score(Xn, yn))\n",
    "print ('Confusion Matrix \\n')\n",
    "print (confusion_matrix(yn, gs_logreg.predict(Xn)))\n",
    "print ('Classification Report\\n')\n",
    "print (classification_report(yn, gs_logreg.predict(Xn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into pairs and work together to do the following.\n",
    "\n",
    "#### Model Generation (30 Minutes)\n",
    "\n",
    "1. Try and create a predictive model that identifies whether a review will be a high-scoring review or not (`high_score` feature in the data). While you can use any of the NLP techniques we discussed yesterday, here are some areas to focus on:\n",
    "\n",
    "1. Should you use `CountVectorizer` or `TfidfVectorizer` to transform your DataFrame?\n",
    "    - Keep stop words or drop them?\n",
    "    - Limit the words going in using `max_df` or `min_df`?\n",
    "2. Apply dimensionality reduction using `TruncatedSVD` or not?\n",
    "    - If you do, how many components should you keep?\n",
    "3. What modeling technique should you use? (`LogisticRegression`, `RandomForestClassifier`, etc.?) How will you change the hyperparameters.\n",
    "\n",
    "Make sure that you are checking your model's performance against the test set.\n",
    "\n",
    "#### Discussion (10 Minutes)\n",
    "\n",
    "A pair from each market will come on mic and discuss how they've chosen to transform their data. Additionally, we'll compare the **mean accuracy** for each market to see who has (at this point) made the most predictive model.\n",
    "\n",
    "#### Model Refinement (10 Minutes)\n",
    "\n",
    "Continue to refine your model or include some choices made by other markets. At the end of these 10 minutes, we'll report each market's best finding (and final model) by mic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Techniques\n",
    "\n",
    "Today's lesson is designed as an introduction to more advanced libraries or techniques in the realm of Natural Language Processing. These techniques can help you gain even greater accuracy in your modeling, but require more in-depth knowledge of new libraries, new techniques, etc. \n",
    "\n",
    "While we'll be introducing a lot of new material today, we'll be doing our best to limit the discussion to what is most immediately helpful. Each of these libraries and techniques has much more going on than we have time to discuss this week and we encourage you to spend time investigating and understanding these libraries. However, **mastery of these libraries, techniques, and materials introduced today is not required nor expected.**\n",
    "\n",
    "For Project 4 and your Capstone Project, if you are pursuing an NLP approach, these libraries may be very helpful. However, you can get a lot of mileage out of refining and using the sklearn libraries that we discussed yesterday. A good workflow is to try simple answers first and move into more advanced techniques as your use-case requires -- your goals as modelers should be to make best choice that you can, contingent on time and use-case. Having something work, but not be 100% correct is better than having something 100% correct that doesn't work yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `spacy` to extract parts of speech and named entities\n",
    "\n",
    "[`spaCy`](https://spacy.io/) is a large-scale NLP and text processing library designed to help you extract useful information from text in a speedy and accurate manner. You can imagine it like `CountVectorizer()` turned up to 11. It has underpinnings to C to increase speed and a focus on usability.\n",
    "\n",
    "`spaCy` does *so* much more than we are able to discuss at this point. It is quickly becoming the go-to library for text processing and feature extraction for text. Today, we'll use it to extract parts of speech and named entities.\n",
    "\n",
    "### Parts of Speech\n",
    "\n",
    "We may want to use some derived statistics about parts of speech in our work as Data Scientists, either as the inputs to a model (document _x_ is _y_% verbs) or to help us modify the inputs to a model (we may want to treat `book` the verb differently than `book` the noun). While many different libraries can do parts of speech (`textblob`, which we'll introduce shortly, can do that as well), we'll introduce this using `spaCy`.\n",
    "\n",
    "First, we set up some text from Wikipedia to parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago ( ( listen) or ), officially the City of Chicago, is the third-most populous city in the United States. With over 2.7 million residents, it is also the most populous city in both the state of Illinois and the Midwestern United States. It is the county seat of Cook County. The Chicago metropolitan area, often referred to as Chicagoland, has nearly 10 million people and is the third-largest in the United States. Chicago has often been called a global architecture capital and is considered \n"
     ]
    }
   ],
   "source": [
    "chicago = wikipedia.page('chicago')\n",
    "\n",
    "print(chicago.content[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create sentences by splitting on `.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chicago ( ( listen) or ), officially the City of Chicago, is the third-most populous city in the United States',\n",
       " 'With over 2.7 million residents, it is also the most populous city in both the state of Illinois and the Midwestern United States',\n",
       " 'It is the county seat of Cook County',\n",
       " 'The Chicago metropolitan area, often referred to as Chicagoland, has nearly 10 million people and is the third-largest in the United States',\n",
       " 'Chicago has often been called a global architecture capital and is considered one of the most important business centers in the world.\\nChicago was incorporated as a city in 1837 near a portage between the Great Lakes and the Mississippi River watershed and grew rapidly in the mid-nineteenth century']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicago_sents = chicago.content.split('. ')\n",
    "chicago_sents[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set up a model in `spaCy`. This lets `spaCy` know what to use as its internal corpus. We name this model `nlp` by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_sents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll feed a sentence into `nlp`. This will automatically split the text into a generator of tokens (one token to each word). These tokens will have the part of speech already tagged in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over 2.7 million residents, it is also the most populous city in both the state of Illinois and the Midwestern United States\n",
      "With ADP\n",
      "over ADP\n",
      "2.7 NUM\n",
      "million NUM\n",
      "residents NOUN\n",
      ", PUNCT\n",
      "it PRON\n",
      "is VERB\n",
      "also ADV\n",
      "the DET\n",
      "most ADV\n",
      "populous ADJ\n",
      "city NOUN\n",
      "in ADP\n",
      "both CCONJ\n",
      "the DET\n",
      "state NOUN\n",
      "of ADP\n",
      "Illinois PROPN\n",
      "and CCONJ\n",
      "the DET\n",
      "Midwestern PROPN\n",
      "United PROPN\n",
      "States PROPN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(chicago_sents[1])\n",
    "print(doc)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to convert this into a set of part of speech tags, we could add in a little extra Python to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADP': 4, 'NUM': 2, 'NOUN': 3, 'PUNCT': 1, 'PRON': 1, 'VERB': 1, 'ADV': 2, 'DET': 3, 'ADJ': 1, 'CCONJ': 2, 'PROPN': 4}\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for token in doc:\n",
    "    if token.pos_ not in tags.keys():\n",
    "        tags[token.pos_] = 1\n",
    "    else:\n",
    "        tags[token.pos_] += 1\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more tags to that `spaCy` can provide for us:\n",
    "\n",
    "- Text: The original word text.\n",
    "- Lemma: The base form of the word.\n",
    "- POS: The simple part-of-speech tag.\n",
    "- Tag: The detailed part-of-speech tag.\n",
    "- Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "- Shape: The word shape – capitalisation, punctuation, digits.\n",
    "- is alpha: Is the token an alpha character?\n",
    "- is stop: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I am in a bootcamp right now and it has become a difficult challenge for me.'\n",
    "doc= nlp(sent)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"I love to watch my watch tick\"\n",
    "doc = nlp(sent)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tLemma\tPOS\tDetailed POS\tDependency\tShape\tIs alphabetic?\tIs stopword?\n",
      "With\twith\tADP\tIN\tprep\tXxxx\tTrue\tFalse\n",
      "over\tover\tADP\tIN\tquantmod\txxxx\tTrue\tTrue\n",
      "2.7\t2.7\tNUM\tCD\tcompound\td.d\tFalse\tFalse\n",
      "million\tmillion\tNUM\tCD\tnummod\txxxx\tTrue\tFalse\n",
      "residents\tresident\tNOUN\tNNS\tpobj\txxxx\tTrue\tFalse\n",
      ",\t,\tPUNCT\t,\tpunct\t,\tFalse\tFalse\n",
      "it\t-PRON-\tPRON\tPRP\tnsubj\txx\tTrue\tTrue\n",
      "is\tbe\tVERB\tVBZ\tROOT\txx\tTrue\tTrue\n",
      "also\tconjurer\tADV\tRB\tadvmod\txxxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "most\tmuch\tADV\tRBS\tadvmod\txxxx\tTrue\tTrue\n",
      "populous\tpopulous\tADJ\tJJ\tamod\txxxx\tTrue\tFalse\n",
      "city\tcity\tNOUN\tNN\tattr\txxxx\tTrue\tFalse\n",
      "in\tin\tADP\tIN\tprep\txx\tTrue\tTrue\n",
      "both\tboth\tCCONJ\tCC\tpredet\txxxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "state\tstate\tNOUN\tNN\tpobj\txxxx\tTrue\tFalse\n",
      "of\tof\tADP\tIN\tprep\txx\tTrue\tTrue\n",
      "Illinois\tillinois\tPROPN\tNNP\tpobj\tXxxxx\tTrue\tFalse\n",
      "and\tand\tCCONJ\tCC\tcc\txxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "Midwestern\tmidwestern\tPROPN\tNNP\tcompound\tXxxxx\tTrue\tFalse\n",
      "United\tunited\tPROPN\tNNP\tcompound\tXxxxx\tTrue\tFalse\n",
      "States\tstates\tPROPN\tNNP\tconj\tXxxxx\tTrue\tFalse\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(['Text', 'Lemma', 'POS', 'Detailed POS', 'Dependency',\n",
    "                'Shape', 'Is alphabetic?', 'Is stopword?']))\n",
    "for token in doc:\n",
    "    print('\\t'.join([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, str(token.is_alpha), str(token.is_stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check For Understanding 1 (10 minutes)\n",
    "\n",
    "With a partner, do the following:\n",
    "\n",
    "1. Pick two different wikipedia articles\n",
    "2. Get the content using the `wikipedia` library\n",
    "3. Using `spacy`, derive the following:\n",
    "    1. How many tokens are in your article?\n",
    "    2. How many parts of speech are in each article? How often do they occur?\n",
    "    3. As a percentage of the total number of tokens, how often does each part of speech occur?\n",
    "4. Does it look like there's a difference across your documents? What other types of documents would have different distributions of parts of speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lampreys (sometimes also called, inaccurately, lamprey eels) are any jawless fish of the order Petromyzontiformes, placed in the superclass Cyclostomata. The adult lamprey may be characterized by a toothed, funnel-like sucking mouth. The common name \"lamprey\" is probably derived from Latin lampetra, which may mean \"stone licker\" (lambere \"to lick\" + petra \"stone\"), though the etymology is uncertain.\n",
      "There are about 38 known extant species of lampreys. Parasitic species are the best known, and fe\n"
     ]
    }
   ],
   "source": [
    "lamprey = wikipedia.page('Lamprey')\n",
    "\n",
    "print(lamprey.content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hagfish, the class Myxini (also known as Hyperotreti), are eel-shaped, slime-producing marine fish (occasionally called slime eels). They are the only known living animals that have a skull but no vertebral column, although hagfish do have rudimentary vertebrae. Along with lampreys, hagfish are jawless; they are the sister group to vertebrates, and living hagfish remain similar to hagfish from around 300 million years ago.\n",
      "The classification of hagfish had been controversial. The issue was wheth\n"
     ]
    }
   ],
   "source": [
    "hagfish = wikipedia.page('Hagfish')\n",
    "print(hagfish.content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lampreys (sometimes also called, inaccurately, lamprey eels) are any jawless fish of the order Petromyzontiformes, placed in the superclass Cyclostomata',\n",
       " 'The adult lamprey may be characterized by a toothed, funnel-like sucking mouth',\n",
       " 'The common name \"lamprey\" is probably derived from Latin lampetra, which may mean \"stone licker\" (lambere \"to lick\" + petra \"stone\"), though the etymology is uncertain.\\nThere are about 38 known extant species of lampreys',\n",
       " 'Parasitic species are the best known, and feed by boring into the flesh of other fish to suck their blood; but only 18 species of lampreys are parasitic',\n",
       " 'Parasitic lampreys also attach themselves to larger animals to get a free ride',\n",
       " 'Adults of the non-parasitic species do not feed; they live off reserves acquired as ammocoetes (larvae), which they obtain through filter feeding.\\nThe lampreys are a very ancient lineage of vertebrates, though their exact relationship to hagfishes and jawed vertebrates is still a matter of dispute.\\n\\n\\n== Characteristics ==\\n\\nAdults superficially resemble eels in that they have scaleless,elongated bodies, and can range from 13 to 100 cm (5 to 40 inches) in length',\n",
       " 'Lacking paired fins, adult lampreys have large eyes, one nostril on the top of the head, and seven gill pores on each side of the head',\n",
       " \"The pharynx is subdivided; the ventral part forming a respiratory tube that is isolated from the mouth by a valve called the velum.\\nThis is an adaptation to how the adults feed, by preventing the prey's body fluids from escaping through the gills or interfering with gas exchange, which takes place by pumping water in and out of the gill pouches instead of taking it in through the mouth\",\n",
       " 'Near the gills are the eyes, which are poorly developed and buried under skin in the larvae',\n",
       " 'The eyes complete their development during metamorphosis, and in adults are covered by a thin and transparent layer of skin that becomes opaque in preservatives.\\nThe unique morphological characteristics of lampreys, such as their cartilaginous skeleton, suggest they are the sister taxon (see cladistics) of all living jawed vertebrates (gnathostomes), and are usually considered the most basal group of the Vertebrata',\n",
       " 'Instead of true vertebrae, they have a series of cartilaginous structures called arcualia arranged above the notochord',\n",
       " 'Hagfish, which resemble lampreys, have traditionally been considered the sister taxon of the true vertebrates (lampreys and gnathostomes) but DNA evidence suggests that they are in fact the sister taxon of lampreys.\\nStudies have shown that lampreys are amongst the most energy-efficient swimmers',\n",
       " \"Their swimming movements generate low-pressure zones around their body, which pull rather than push their bodies through the water.\\nParasitic lampreys feed on prey as adults by attaching their mouthparts to the target animal's body, then using their teeth to cut through surface tissues until they reach blood and body fluid\",\n",
       " 'A study of stomach content of some lampreys have also shown remains of intestines, fins and vertebrae from their prey',\n",
       " 'Although attacks on humans do occur, they will generally not attack humans unless starved',\n",
       " 'Non-parasitic lampreys, which are usually freshwater species, do not feed as adults; they live off reserves acquired as ammocoetes (larvae), which they obtain through filter feeding.\\nLampreys provide valuable insight into adaptive immune systems, as they possess a convergently evolved adaptive immunity with cells that function like the T cells and B cells seen in higher vertebrates',\n",
       " 'Lamprey leukocytes express surface variable lymphocyte receptors (VLRs) generated from somatic recombination of leucine-rich repeat gene segments in a recombination activating gene-independent manner.\\nNorthern lampreys (Petromyzontidae) have the highest number of chromosomes (164–174) among vertebrates.\\nPouched lamprey (Geotria australis) larvae also have a very high tolerance for free iron in their bodies, and have well-developed biochemical systems for detoxification of the large quantities of these metal ions.\\n\\n\\n=== Lifecycle ===\\n\\nAdult lampreys spawn in rivers and then die',\n",
       " 'The young larvae, ammocoetes, spend several years in the rivers, where they live burrowed in fine sediment, filter feeding on detritus and microorganisms',\n",
       " 'Then, ammocoetes undergo a metamorphosis lasting several months.\\nSome species do not feed after metamorphosis, while others migrate to the sea or lakes, where they feed on different species of fish and even on marine mammals',\n",
       " 'Species whose adults migrate to the sea begin preying on other fish soon after metamorphosis, even as they begin swimming downstream.\\n\\n\\n=== Use in research ===\\n\\nThe lamprey has been extensively studied because its relatively simple brain is thought in many respects to reflect the brain structure of early vertebrate ancestors',\n",
       " 'Beginning in the 1970s, Sten Grillner and his colleagues at the Karolinska Institute in Stockholm followed on from extensive work on the lamprey started by Carl Rovainen in the 1960s that used the lamprey as a model system to work out the fundamental principles of motor control in vertebrates starting in the spinal cord and working toward the brain.\\nIn a series of studies by Rovainen and his student James Buchanan, the cells that formed the neural circuits within the spinal cord capable of generating the rhythmic motor patterns that underlie swimming were examined',\n",
       " 'Note that there are still missing details in the network scheme despite claims by Grillner that the network is characterised (Parker 2006, 2010)',\n",
       " 'Spinal cord circuits are controlled by specific locomotor areas in the brainstem and midbrain, and these areas are in turn controlled by higher brain structures, including the basal ganglia and tectum.\\nIn a study of the lamprey tectum published in 2007, they found electrical stimulation could elicit eye movements, lateral bending movements, or swimming activity, and the type, amplitude, and direction of movement varied as a function of the location within the tectum that was stimulated',\n",
       " 'These findings were interpreted as consistent with the idea that the tectum generates goal-directed locomotion in the lamprey.\\nLampreys are used as a model organism in biomedical research, where their large reticulospinal axons are used to investigate synaptic transmission',\n",
       " 'The axons of lamprey are particularly large and allow for microinjection of substances for experimental manipulation.\\n\\n\\n== Distribution ==\\n\\nLampreys live mostly in coastal and fresh waters, although some species (e.g',\n",
       " 'Geotria australis, Petromyzon marinus, and Entosphenus tridentatus) travel significant distances in the open ocean, as evidenced by their lack of reproductive isolation between populations',\n",
       " 'Some species are found in land-locked lakes',\n",
       " 'They are found in most temperate regions except those in Africa',\n",
       " 'Their larvae (ammocoetes) have a low tolerance for high water temperatures, which may explain why they are not distributed in the tropics.\\nLamprey distribution may be adversely affected by overfishing and pollution',\n",
       " 'In Britain, at the time of the Conquest, lampreys were found as far upstream in the River Thames as Petersham',\n",
       " 'Reduction of pollution in the Thames and River Wear has led to recent sightings in London and Chester-le-Street.\\nDistribution may also be adversely affected by dams and other construction projects disrupting migration routes, obstructing access to spawning grounds',\n",
       " 'Conversely, the construction of artificial channels has exposed new habitats for colonisation notably in North America where sea lampreys have become a significant introduced pest in the Great Lakes',\n",
       " 'Active control programs to control lampreys are undergoing modifications due to concerns of drinking water quality in some areas.\\n\\n\\n== Taxonomy and systematics ==\\n\\nTaxonomists place lampreys and hagfish in the subphylum Vertebrata of the phylum Chordata, which also includes the invertebrate subphyla Tunicata (sea-squirts) and the fish-like Cephalochordata (lancelets or Amphioxus)',\n",
       " 'Recent molecular and morphological phylogenetic studies place lampreys and hagfish in the superclass Agnatha or Agnathostomata (both meaning without jaws)',\n",
       " 'The other vertebrate superclass is Gnathostomata (jawed mouths) and includes the classes Chondrichthyes (sharks), Osteichthyes (bony fishes), Amphibia, Reptilia, Aves, and Mammalia.\\nSome researchers have classified lampreys as the sole surviving representatives of the Linnean class Cephalaspidomorphi',\n",
       " 'Cephalaspidomorpha is sometimes given as a subclass of the Cephalaspidomorphi',\n",
       " 'Fossil evidence now suggests lampreys and cephalaspids acquired their shared characters by convergent evolution',\n",
       " 'As such, many newer works, such as the fourth edition of Fishes of the World, classify lampreys in a separate group called Hyperoartia or Petromyzontida, but whether this is actually a clade is disputed',\n",
       " 'Namely, it has been proposed that the non-lamprey \"Hyperoartia\" are in fact closer to the jawed vertebrates.\\nThe debate about their systematics notwithstanding, lampreys constitute a single order Petromyzontiformes',\n",
       " 'Sometimes still seen is the alternative spelling \"Petromyzoniformes\", based on the argument that the type genus is Petromyzon and not \"Petromyzonta\" or similar',\n",
       " 'Throughout most of the 20th century, both names were used pretty much indiscriminately, even by the same author in subsequent publications',\n",
       " 'In the mid-1970s, the ICZN was called upon to fix one name or the other, and after much debate had to resolve the issue by voting',\n",
       " 'Thus, in 1980, the spelling with a \"t\" won out, and in 1981, it became official that all higher-level taxa based on Petromyzon have to start with \"Petromyzont-\".\\nThe following taxonomy is based upon the treatment by FishBase as of April 2012 with phylogeny compiled by Mikko Haaramo',\n",
       " 'Within the order are 10 living genera in three families',\n",
       " 'Two of the latter are monotypic at genus level today, and in one of them a single living species is recognized (though it may be a cryptic species complex):\\n\\n\\n=== Fossil record ===\\n\\nLamprey fossils are rare because cartilage does not fossilize as readily as bone',\n",
       " 'The first fossil lampreys were originally found in Early Carboniferous limestones, marine sediments in North America: Mayomyzon pieckoensis and Hardistiella montanensis, from the Mississippian Mazon Creek lagerstätte and the Bear Gulch limestone sequence.\\nIn the 22 June 2006 issue of Nature, Mee-mann Chang and colleagues reported on a fossil lamprey from the Yixian Formation of Inner Mongolia',\n",
       " 'The new species, morphologically similar to Carboniferous and other forms, was given the name Mesomyzon mengae (\"Meng Qingwen\\'s Mesozoic lamprey\").\\nThe exceedingly well-preserved fossil showed a well-developed sucking oral disk, a relatively long branchial apparatus showing a branchial basket, seven gill pouches, gill arches, and even the impressions of gill filaments, and about 80 myomeres of its musculature',\n",
       " 'Unlike the North American fossils, its habitat was almost certainly fresh water.\\nMonths later, a fossil lamprey even older than the Mazon Creek genera was reported from Witteberg Group rocks near Grahamstown, in the Eastern Cape of South Africa',\n",
       " 'This species, Priscomyzon riniensis, is very similar to lampreys found today.\\n\\n\\n== As pests ==\\n\\nSea lampreys have become a major pest in the North American Great Lakes',\n",
       " 'It is generally believed that they gained access to the lakes via canals during the early 20th century, but this theory is controversial',\n",
       " 'They are considered an invasive species, have no natural enemies in the lakes, and prey on many species of commercial value, such as lake trout.\\nLampreys are now found mostly in the streams that feed the lakes, and controlled with special barriers to prevent the upstream movement of adults, or by the application of toxicants called lampricides, which are harmless to most other aquatic species; however, those programs are complicated and expensive, and do not eradicate the lampreys from the lakes, but merely keep them in check.\\nNew programs are being developed, including the use of chemically sterilized male lampreys in a method akin to the sterile insect technique',\n",
       " 'Finally, pheromones critical to lamprey migratory behaviour have been isolated, their chemical structures determined, and their impact on lamprey behaviour studied, in the laboratory and in the wild, and active efforts are underway to chemically source and to address regulatory considerations that might allow this strategy to proceed.\\nControl of sea lampreys in the Great Lakes is conducted by the U.S',\n",
       " 'Fish and Wildlife Service and the Canadian Department of Fisheries and Oceans, and is coordinated by the Great Lakes Fishery Commission',\n",
       " \"Lake Champlain, bordered by New York, Vermont, and Quebec, and New York's Finger Lakes are also home to high populations of sea lampreys that warrant control\",\n",
       " \"Lake Champlain's lamprey control program is managed by the New York State Department of Environmental Conservation, the Vermont Department of Fish and Wildlife, and the U.S\",\n",
       " 'Fish and Wildlife Service',\n",
       " \"New York's Finger Lakes sea lamprey control program is managed solely by the New York State Department of Environmental Conservation.\\n\\n\\n== In human culture ==\\n\\n\\n=== As food ===\\n\\nLampreys have long been used as food for humans\",\n",
       " 'they are described to be more \"tertiary\" or \"meaty\" than a traditional fish They were highly appreciated by ancient Romans',\n",
       " 'During the Middle Ages, they were widely eaten during this time by the upper classes throughout Europe, especially during Lent as fish is exempt from the prohibition of meat',\n",
       " 'King Henry I of England is claimed to have been so fond of lampreys that he often ate them late into life and poor health against the advice of his physician concerning their richness, and is said to have died from eating \"a surfeit of lampreys\"',\n",
       " \"Whether or not his lamprey indulgence actually caused his death is unclear.\\nOn 4 March 1953, Queen Elizabeth II's coronation pie was made by the Royal Air Force using lampreys.\\nIn southwestern Europe (Portugal, Spain, and France), in the northern half in Finland and generally in Latvia (where lamprey is routinely sold in supermarkets), larger lampreys are still a highly prized delicacy\",\n",
       " 'Sea lamprey is the most sought-after species in Portugal and one of only two that can legally bear the commercial name \"lamprey\" (lampreia): the other one being Lampetra fluviatilis, the European river lamprey, both according to Portaria (Government regulation no',\n",
       " '587/2006, from 22 June)',\n",
       " 'Overfishing has reduced their number in those parts',\n",
       " 'Lampreys are also consumed in Sweden, Finland, Russia, New Zealand, the Baltic countries, Japan, and South Korea',\n",
       " 'In Finland, they are commonly sold pickled in vinegar.\\nThe mucus and serum of several lamprey species, including the Caspian lamprey (Caspiomyzon wagneri), river lampreys (Lampetra fluviatilis and L',\n",
       " 'planeri), and sea lamprey (Petromyzon marinus), are known to be toxic, and require thorough cleaning before cooking and consumption.\\nIn Britain, lampreys are commonly used as bait, normally as dead bait',\n",
       " 'Northern pike, perch, and chub all can be caught on lampreys',\n",
       " 'Frozen lampreys can be bought from most bait and tackle shops.\\n\\n\\n=== In folklore ===\\nIn folklore, lampreys are called \"nine-eyed eels\"',\n",
       " \"The name is derived from the seven external gill slits which, along with one nostril and one eye, line each side of a lamprey's head section\",\n",
       " 'Likewise, the German word for lamprey is Neunauge, which means \"nine-eye\", and in Japanese they are called yatsume-unagi (八つ目鰻, \"eight-eyed eels\"), which excludes the nostrils from the count.\\n\\n\\n=== In literature ===\\n\\nVedius Pollio kept a pool of lampreys into which slaves who incurred his displeasure would be thrown as food',\n",
       " 'On one occasion, Vedius was punished by Augustus for attempting to do so in his presence:\\n\\n...one of his slaves had broken a crystal cup',\n",
       " 'Vedius ordered him to be seized and then put to death, but in an unusual way',\n",
       " 'He ordered him to be thrown to the huge lampreys which he had in his fish pond',\n",
       " 'Who would not think he did this for display? Yet it was out of cruelty',\n",
       " \"The boy slipped from the captor's hands and fled to Augustus' feet asking nothing else other than a different way to die – he did not want to be eaten\",\n",
       " 'Augustus was moved by the novelty of the cruelty and ordered him to be released, all the crystal cups to be broken before his eyes, and the fish pond to be filled in...\\n\\nThis incident was incorporated into the plot of the 2003 novel Pompeii by Robert Harris in the incident of Ampliatus feeding a slave to his lampreys.\\nLucius Licinius Crassus was mocked by Gnaeus Domitius Ahenobarbus (cos',\n",
       " '54 BC) for weeping over the death of his pet lamprey:\\n\\nSo, when Domitius said to Crassus the orator, Did not you weep for the death of the lamprey you kept in your fish pond? – Did not you, said Crassus to him again, bury three wives without ever shedding a tear? – Plutarch, On the Intelligence of Animals, 976a\\n\\nThis story is also found in Aelian (Various Histories VII, 4) and Macrobius (Saturnalia III.15.3)',\n",
       " 'It is included by Hugo von Hofmannsthal in the Chandos Letter:\\n\\nAnd in my mind I compare myself from time to time with the orator Crassus, of whom it is reported that he grew so excessively enamoured of a tame lamprey – a dumb, apathetic, red-eyed fish in his ornamental pond – that it became the talk of the town; and when one day in the Senate Domitius reproached him for having shed tears over the death of this fish, attempting thereby to make him appear a fool, Crassus answered, \"Thus have I done over the death of my fish as you have over the death of neither your first nor your second wife.\"\\nI know not how oft this Crassus with his lamprey enters my mind as a mirrored image of my Self, reflected across the abyss of centuries.\\n\\nIn George R',\n",
       " 'R',\n",
       " 'Martin\\'s novel series, A Song of Ice and Fire, Lord Wyman Manderly is mockingly called \"Lord Lamprey\" by his subjects in reference to his rumored affinity to lamprey pie and his striking obesity.\\nKurt Vonnegut, in his late short story \"The Big Space Fuck\", posits a future America so heavily polluted – \"Everything had turned to shit and beer cans\", in his words – that the Great Lakes have been infested with a species of massive, ambulatory lampreys; all three of the main characters are eaten by lampreys on leaving a house near the end of the story.\\n\\n\\n== List of species ==\\nTaxonomic list based on FishBase 2017.\\nGeotria australis Gray 1851 (Pouched lamprey)\\nMordacia lapicida (Gray 1851) (Chilean lamprey)\\nMordacia mordax (Richardson 1846) (Australian lamprey)\\nMordacia praecox Potter 1968 (Non-parasitic/Australian brook lamprey)\\nPetromyzon marinus Linnaeus 1758 (Sea lamprey)\\nIchthyomyzon bdellium (Jordan 1885) (Ohio lamprey)\\nIchthyomyzon castaneus Girard 1858 (Chestnut lamprey)\\nIchthyomyzon fossor Reighard & Cummins 1916 (Northern brook lamprey)\\nIchthyomyzon gagei Hubbs & Trautman 1937 (Southern brook lamprey)\\nIchthyomyzon greeleyi Hubbs & Trautman 1937 (Mountain brook lamprey)\\nIchthyomyzon unicuspis Hubbs & Trautman 1937 (Silver lamprey)\\nCaspiomyzon wagneri (Kessler 1870) Berg 1906 (Caspian lamprey)\\nCaspiomyzon graecus (Renaud & Economidis 2010) (Ionian brook lamprey)\\nCaspiomyzon hellenicus (Vladykov et al',\n",
       " \"1982) (Greek lamprey)\\nTetrapleurodon geminis Álvarez 1964 (Mexican brook lamprey)\\nTetrapleurodon spadiceus (Bean 1887) (Mexican lamprey)\\nEntosphenus folletti Vladykov & Kott 1976 (Northern California brook lamprey)\\nEntosphenus lethophagus (Hubbs 1971) (Pit-Klamath brook lamprey)\\nEntosphenus macrostomus (Beamish 1982) (Lake lamprey)\\nEntosphenus minimus (Bond & Kan 1973) (Miller Lake lamprey)\\nEntosphenus similis Vladykov & Kott 1979 (Klamath river lamprey)\\nEntosphenus tridentatus (Richardson 1836) (Pacific lamprey)\\nLethenteron alaskense Vladykov & Kott 1978 (Alaskan brook lamprey)\\nLethenteron appendix (DeKay 1842) (American brook lamprey)\\nLethenteron camtschaticum (Tilesius 1811) (Arctic lamprey)\\nLethenteron kessleri (Anikin 1905) (Siberian brook lamprey)\\nLethenteron ninae Naseka, Tuniyev & Renaud 2009 (Western Transcaucasian lamprey)\\nLethenteron reissneri (Dybowski 1869) (Far Eastern brook lamprey)\\nLethenteron zanandreai (Vladykov 1955) (Lombardy lamprey)\\nEudontomyzon stankokaramani (Karaman 1974) (Drin brook lamprey)\\nEudontomyzon morii (Berg 1931) (Korean lamprey)\\nEudontomyzon danfordi Regan 1911 (Carpathian brook lamprey)\\nEudontomyzon mariae (Berg 1931) (Ukrainian brook lamprey)\\nEudontomyzon vladykovi (Oliva & Zanandrea 1959) (Vladykov's lamprey)\\nLampetra aepyptera (Abbott 1860) (Least brook lamprey)\\nLampetra alavariensis Mateus et al\",\n",
       " '2013 (Portuguese lamprey)\\nLampetra auremensis Mateus et al',\n",
       " '2013 (Qurem lamprey)\\nLampetra ayresi (Günther 1870) (Western river lamprey)\\nLampetra fluviatilis (Linnaeus 1758) (European river lamprey)\\nLampetra hubbsi (Vladykov & Kott 1976) (Kern brook lamprey)\\nLampetra lanceolata Kux & Steiner 1972 (Turkish brook lamprey)\\nLampetra lusitanica Mateus et al',\n",
       " '2013 (lusitanic lamprey)\\nLampetra pacifica Vladykov 1973 (Pacific brook lamprey)\\nLampetra planeri (Bloch 1784) (European brook lamprey)\\nLampetra richardsoni Vladykov & Follett 1965 (Western brook lamprey)\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\n\\n\\n=== General ===\\nRenaud, C.B',\n",
       " '(2011) Lampreys of the world',\n",
       " 'An annotated and illustrated catalogue of lamprey species known to date FAO Species Catalogue for Fishery Purposes',\n",
       " 'No',\n",
       " '5',\n",
       " 'Rome',\n",
       " 'ISBN 978-92-5-106928-8.\\n\\n\\n=== Research on pheromones for pest control ===\\nPeter W',\n",
       " 'Sorensen, Jared M',\n",
       " 'Fine, Vadims Dvornikovs, Christopher S',\n",
       " 'Jeffrey, Feng Shao, Jizhou Wang, Lance A',\n",
       " 'Vrieze, Kari R',\n",
       " 'Anderson & Thomas R',\n",
       " 'Hoye, 2005, \"Mixture of new sulfated steroids functions as a migratory pheromone in the sea lamprey,\" Nature Chem',\n",
       " 'Biol',\n",
       " '1:324–328, DOI 10.1038/nchembio739, see [6], accessed 1 July 2015',\n",
       " '[Primary source example.]\\nAndrew Dittman, 2005, \" News and Views: Chemical cues for sea lamprey migration,\" Nature Chem',\n",
       " 'Biol',\n",
       " '1:316 – 317, DOI 10.1038/nchembio1105-316, see [7], accessed 1 July 2015',\n",
       " '[Lay summary of Sorensen, et al',\n",
       " '(2005)]\\nJohnson, Nicholas S.; Yun, Sang-Seon; Thompson, Henry T.; Brant, Cory O.; Li, Weiming (2009)',\n",
       " '\"A synthesized pheromone induces upstream movement in female sea lamprey and summons them into traps\"',\n",
       " 'Proc',\n",
       " 'Natl',\n",
       " 'Acad',\n",
       " 'Sci',\n",
       " 'U.S.A',\n",
       " '106 (4): 1021–1026',\n",
       " 'doi:10.1073/pnas.0808530106',\n",
       " ' [Primary source example.]\\nRichard Black, 2009, \"Sex smell lures \\'vampire\\' to doom,\" BBC News (online), 20 January 2009, see [8], accessed 1 July 2015',\n",
       " '[Lay summary of Johnson, et al',\n",
       " '(2009); Subtitle: \"A synthetic \\'chemical sex smell\\' could help rid North America\\'s Great Lakes of a devastating pest, scientists say.\"]\\n\\n\\n== External links ==\\n\"ITIS report on the lampreys\"',\n",
       " 'ITIS',\n",
       " 'Retrieved 27 September 2012',\n",
       " '\\n\"Lamprey\"',\n",
       " 'Inland Fisheries Ireland',\n",
       " 'Retrieved 27 September 2012',\n",
       " '\\n\"The Tree of Life\"',\n",
       " 'Retrieved 27 September 2012',\n",
       " ' A Tree of Life diagram showing the relation of Lampreys to other organisms.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamprey = lamprey.content.split('. ')\n",
    "lamprey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hagfish_sents = hagfish.content.split('. ')\n",
    "hagfish_sents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "lamp = nlp(lamprey[0:5])\n",
    "\n",
    "for token in lamp:\n",
    "    print(token.text, token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "for token in lamp:\n",
    "    if token.pos_ not in tags.keys():\n",
    "        tags[token.pos_] = 1\n",
    "    else:\n",
    "        tags[token.pos_] += 1\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tLemma\tPOS\tDetailed POS\tDependency\tShape\tIs alphabetic?\tIs stopword?\n",
      "With\twith\tADP\tIN\tprep\tXxxx\tTrue\tFalse\n",
      "over\tover\tADP\tIN\tquantmod\txxxx\tTrue\tTrue\n",
      "2.7\t2.7\tNUM\tCD\tcompound\td.d\tFalse\tFalse\n",
      "million\tmillion\tNUM\tCD\tnummod\txxxx\tTrue\tFalse\n",
      "residents\tresident\tNOUN\tNNS\tpobj\txxxx\tTrue\tFalse\n",
      ",\t,\tPUNCT\t,\tpunct\t,\tFalse\tFalse\n",
      "it\t-PRON-\tPRON\tPRP\tnsubj\txx\tTrue\tTrue\n",
      "is\tbe\tVERB\tVBZ\tROOT\txx\tTrue\tTrue\n",
      "also\tconjurer\tADV\tRB\tadvmod\txxxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "most\tmuch\tADV\tRBS\tadvmod\txxxx\tTrue\tTrue\n",
      "populous\tpopulous\tADJ\tJJ\tamod\txxxx\tTrue\tFalse\n",
      "city\tcity\tNOUN\tNN\tattr\txxxx\tTrue\tFalse\n",
      "in\tin\tADP\tIN\tprep\txx\tTrue\tTrue\n",
      "both\tboth\tCCONJ\tCC\tpredet\txxxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "state\tstate\tNOUN\tNN\tpobj\txxxx\tTrue\tFalse\n",
      "of\tof\tADP\tIN\tprep\txx\tTrue\tTrue\n",
      "Illinois\tillinois\tPROPN\tNNP\tpobj\tXxxxx\tTrue\tFalse\n",
      "and\tand\tCCONJ\tCC\tcc\txxx\tTrue\tTrue\n",
      "the\tthe\tDET\tDT\tdet\txxx\tTrue\tTrue\n",
      "Midwestern\tmidwestern\tPROPN\tNNP\tcompound\tXxxxx\tTrue\tFalse\n",
      "United\tunited\tPROPN\tNNP\tcompound\tXxxxx\tTrue\tFalse\n",
      "States\tstates\tPROPN\tNNP\tconj\tXxxxx\tTrue\tFalse\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(['Text', 'Lemma', 'POS', 'Detailed POS', 'Dependency',\n",
    "                'Shape', 'Is alphabetic?', 'Is stopword?']))\n",
    "for token in doc:\n",
    "    print('\\t'.join([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, str(token.is_alpha), str(token.is_stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities\n",
    "\n",
    "Named entities are business, people, countries, or other things that refer to a specific person, place, or thing (think `Apple`, computer manufacturer versus `apple`, delicious crunchy fruit). `spaCy` can identify named entities for us, which we can either highlight or drop from our analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've parsed a string of text using `spaCy`, we can call out the named entities using the `.ents` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "love VERB\n",
      "to PART\n",
      "watch VERB\n",
      "my ADJ\n",
      "watch NOUN\n",
      "tick NOUN\n"
     ]
    }
   ],
   "source": [
    "sent = 'I love to watch my watch tick'\n",
    "doc = nlp(sent)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love to watch my watch tick <class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "print(doc, type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 2.7 million CARDINAL\n",
      "Illinois GPE\n",
      "the Midwestern United States GPE\n"
     ]
    }
   ],
   "source": [
    "for named_entity in doc.ents:\n",
    "    print(named_entity.text, named_entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`spaCy` provides a set of labels for each type of named entity:\n",
    "\n",
    "|Label|Description|\n",
    "|:-- | :-- |\n",
    "|PERSON |\tPeople, including fictional. |\n",
    "|NORP |\tNationalities or religious or political groups. |\n",
    "|FACILITY |\tBuildings, airports, highways, bridges, etc. |\n",
    "|ORG |\tCompanies, agencies, institutions, etc. |\n",
    "|GPE |\tCountries, cities, states. |\n",
    "|LOC |\tNon-GPE locations, mountain ranges, bodies of water. |\n",
    "|PRODUCT |\tObjects, vehicles, foods, etc. (Not services.) |\n",
    "|EVENT |\tNamed hurricanes, battles, wars, sports events, etc. |\n",
    "|WORK_OF_ART |\tTitles of books, songs, etc. |\n",
    "|LAW |\tNamed documents made into laws. |\n",
    "|LANGUAGE |\tAny named language.|\n",
    "|DATE |\tAbsolute or relative dates or periods. |\n",
    "|TIME |\tTimes smaller than a day. |\n",
    "|PERCENT |\tPercentage, including \"%\".\n",
    "|MONEY |\tMonetary values, including unit. |\n",
    "|QUANTITY |\tMeasurements, as of weight or distance. |\n",
    "|ORDINAL |\t\"first\", \"second\", etc. |\n",
    "|CARDINAL |\tNumerals that do not fall under another type. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to see all the unique named entities in the Chicago page, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chicago ( ( listen) or ), officially the City of Chicago, is the third-most populous city in the United States. With over 2.7 million residents, it is also the most populous city in both the state of Illinois and the Midwestern United States. It is the county seat of Cook County. The Chicago metropolitan area, often referred to as Chicagoland, has nearly 10 million people and is the third-largest in the United States. Chicago has often been called a global architecture capital and is considered '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicago.content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'26 miles', 'Miro', '1987', 'Rahm Emanuel', 'Two', 'Lake Calumet Harbor', 'Ireland', 'Showtime', 'Hispanic', \"People's Parade\", \"the United States'\", 'Ferris', 'North', 'the Hubbard Street Dance Chicago', 'Dutch Wheels', 'roughly 4%', 'Montgomery Ward', '510', '26%', 'more than 100,000', 'From 1995 to 2008', 'The Fourth Presbyterian Church', '26th Street', '41', '2006', 'the Museum of Broadcast Communications', 'the 1940s', 'between 1851 and 1920', 'the Chicago Medical School', 'about 2 days', 'three days', 'Chase Bank', 'over 780,000 square meters', 'Checagou', 'The Chicago Symphony Orchestra', '1893', 'summer', 'Financial Times', '0.7%', 'Taste of Chicago', '2020', 'the Standard Oil Building', 'WMVP', 'Great Lakes', '10,000', 'WMAQ 5', 'Five', 'four consecutive years', '96', 'Buckingham Fountain', 'the City Beautiful Movement', '290', 'GE Transportation', 'Cook County Jail', 'The Roman Catholic Archdiocese', '46', 'Muslims', 'Burnham Park', 'West Loop', 'since 1945', 'the Chicago History Museum', 'ABC', '1.6%', 'the 1850s', 'Sears', 'Dallin', 'the Harris Theater for Music and Dance', 'The Oprah Winfrey Show', 'Early Edition', 'The Lithuanian Opera Company of Chicago', 'between 1958', 'the Shedd Aquarium', 'the United Center', '1930', 'Iroquois County', '1980', 'IL-10', 'John H. Stroger Jr.', 'Grace', 'United Continental Holdings', 'the National Football League', '1956', 'the Chicago Fire Department', 'Taylor Street', 'Amtrak', 'over 1,000,000', 'W-02-03', '1876', 'I.O.', '1998', 'African-American', 'Democrat', 'Bugs Moran', 'Statue of the Republic', 'the Great Lakes region', '58', 'John Root', 'The Bob Newhart Show', 'June 2016', 'the mid-nineteenth century', 'MacCormac College', 'Best Sports City', 'Aging, Health & Society', '°F', '90%', '490', '415', 'Jim Nutt', 'Division', 'Onion', 'Inland Northern American', 'Navy', \"Benjamin Ferguson's\", 'the Francis W. Parker School', 'the McCormick Place Convention Center', 'Charlie Trotter', 'Northern American', 'the Chicago Botanic Garden', 'the Maxwell Street', '1997', 'Polish Patches', \"the Women's National Basketball Association\", 'Loyola University Chicago', 'Orange, Brown, Purple, Pink', 'the years', 'Midway Airport', '3 million', '91', 'the Illinois River', 'Julius Rosenwald', 'Humboldt Park', 'AL', 'Thai', '1993, 2006', 'the Chicago Sanitary and Ship Canal', 'The Robie House', 'Greek', 'Columbia College Chicago', 'Democratic National Convention', 'the Sinaloa Cartel', 'the Chicago Board Options Exchange', 'Groupon, Feedburner', 'Streeterville', 'The Merchandise Mart', \"Edward Kemys's\", 'Harry Caray', '13.4%', 'the last two decades of the 19th century', 'Tony Accardo', 'the end of the 19th century', 'Poetry', 'Northwest Indiana', 'Havliček', 'the Chicago Regional Port District', 'Florida', 'every year', 'Langston Hughes', '79', 'the Chicago City Council', 'Central Chicago\\n', 'Little Italy', '1866', '24‑hour', 'Royal Baths', '160', 'the Chicago Reader', 'the Midwestern United States', 'National Register of Historic Places', 'Blue Shield Association', 'Alexander Calder', 'Chopin Park', 'Rockford', 'Wood Street', '1992', 'bin', 'Commonwealth Edison', '97', 'Integrys Energy Group', '1,200 acres', 'The Loop', 'the century', 'McKenna', 'the Chicago Cardinals', 'San Francisco', '1908', 'one day', 'Grand Calumet River', 'the National Hockey League', 'the Chicago Metropolitan Area', 'annual', 'Kane', 'the Steppenwolf Theatre Company and Victory Gardens Theater', 'Milwaukee', 'Chicago Cultural Center', 'The South Side', '1871', '42,063', 'Detroit', 'Desi', 'nearly 10 million', 'Democratic', 'McHenry', 'WGN', 'Marist High School', 'Chicago Innerview', 'Chicago Festival Ballet', 'Las Vegas', '12.5%', '21.4%', 'Croatians', 'Oldenburg', '2013–2014 20th Day', 'Lithuanians', 'Korean', '410', 'Lane Technical College Prep High School', \"Prentice Women's Hospital\", 'Vietnamese', 'Cabrini', '47,074', '10%', 'Midway', 'Society for Clinical Pathology', 'Native American', 'Sinister 2 and Suicide Squad', 'Chicago Fire', 'GE Healthcare', 'The Institute for Clinical Social Work', 'August 12, 1833', '416', 'John Ashbery', 'Buddhists', '66', '5.5%', 'Jane Addams', 'COMEX', 'the Adler Planetarium & Astronomy Museum', 'Latin', '2007', 'Pier', 'the South Side', 'the 1980s', 'World War II', 'the Great Lakes', 'AP', 'Hong Kong', 'December 2, 1942', 'Brewster', 'Reagan', 'Missouri Valley Conference', \"St. Adalbert's Church\", 'the Fine Arts Building', 'Harriet Monroe', 'Gary', 'Strachovský', 'Lithuanian Chicagoans', 'U.S. House', 'the City of Chicago', 'Founder of Chicago', 'the Ida Crown Jewish Academy', '1993', 'The Chicagoland Chamber of Commerce', 'the Chicago Public Library', 'Northerly Island', 'the Pitchfork Music Festival', 'the University of Chicago Medical Center', 'American Dental Association', '1969', \"the U.S. Census Bureau's\", 'the Great Depression', 'Notes', \"Humboldt Park's Institute of Puerto Rican Arts\", 'the National Museum of Mexican Art', '93', 'about $658.6 billion', 'Defender', 'Cook County', 'Ellen Gates Starr', '24.3', 'the 1880s and 1890s', '397', '1945', 'summer months', 'the 1850s and', 'about $640 billion', 'the UIC Flames', 'Willis', 'Memorial Parks', '452', 'Caribbean', 'Chicago Med', 'Jens Ludwig', 'about 70', 'Pilsen', '1892', 'Saint-Gaudens', 'StreetWise', 'CareerBuilder', 'Graduate Medical Education', 'MLS', 'Family Matters', 'twenty-six miles', 'about 4 miles', 'Watch Dogs', 'the Western Wheel Company', 'Orlando', '14 million bushels', '1850 to 1890', 'Each year', '449', '1965', 'Saint Xavier University', 'the Globalization and World Cities Research Network', 'NBC', '1919', 'the Northwest Indian War', 'Deerfield', 'English', '2014–2016', 'the Ping Tom Memorial Park', 'Jean Dubuffet', 'the U.S. Army Corps of Engineers', 'The Frugal Gourmet', 'American League', 'North American', \"Don't Tell Me\", 'Grant Achatz', 'NHL', 'the Ford Center for the Performing Arts Oriental Theatre, Bank of America Theatre', '10.4', 'the Kansas', 'Home Alone', '15.94', 'Lutheran', 'Receiver of Public Monies', '75.8', '2,600', 'the University of Illinois at Chicago', 'America', '20', 'Major League Soccer', 'the late 1920s', 'sixth', 'more than 14%', 'Grundy', 'the National League', 'between 1955 and 1971', 'more than one', '672', 'Lake Calumet', 'the 1980s and 90s', 'World Series', 'Dan Ryan', 'Auditorium Building', 'hundreds', 'the Institute of Gerontology', 'the 1780s', 'Beltway', 'Kendall', 'Music of the Baroque', 'Mother Teresa', 'the Evangelical Covenant Church', 'Dubuffet', 'the British School of Chicago', '2004', 'Irish', 'Boystown', '0.5%', 'Walter Payton', '90', 'Flamingo', '970', 'over 20 million', '$2.5 billion', 'Carbondale', '1933', \"St. Valentine's Day Massacre\", 'The Midwestern University Chicago College of Osteopathic Medicine', 'Jackson Park', 'Chicago Academy for the Arts', 'Exposition', 'James Merrill', '1889', 'Agora', 'Calumet Harbor', 'Metra', 'West Ridge', 'Bosnians', 'East–West University', 'Claes Oldenburg', 'Barbara Rossi', '910', 'Fort Dearborn', 'seven years later', 'Logan', 'NowSecure', 'Symphony Center', '2005', '176.2 m', 'Abakanowicz', 'The Man (a.k.a', 'Ogden', 'third', 'sixteen', 'Lake Shore Drive', '2008', '1867', 'Irv Kupcinet', '943', 'Super Bowl', 'the Chicago River', 'Wrigley', '80', '2001', '2016', 'the Century of Progress International Exposition Worlds Fair', 'Downers Grove', 'One', 'the Commodities Exchange Inc.', '1940 to 1979', 'Masaryk', 'The Museum Campus', 'Grand Rapids', 'Plensa', 'Daley Plaza', 'nearly two-thirds', 'Wiki', 'The Regional Transportation Authority', 'The CME Group', 'the Chicago Architecture Foundation', '200th', '11', 'DePaul University', \"Lamb Chop's\", '1.2%', 'Charles B. Atwood', 'Heald Square Monument', 'North Side Chicago\\n', 'the first half of 2013', 'Belmont Avenue', 'Baxter International', 'South Side Chicago', 'Archer Daniels Midland', 'about 300', 'Time Out Chicago', 'South Shore Line', 'the Soviet Union', '1848', 'the Chicago Bears', 'the Moody Bible Institute', 'ThyssenKrupp North America', 'annually', 'West Sides', 'General Electric', 'The Joffrey Ballet', 'Kankakee', 'the Public Land Survey System', 'Rice High School', 'Tower', 'Mount Carmel High School', 'The North Side', 'Mexican', 'Cumulus Media-owned', 'the early 20th century', 'daily', 'Cloud Gate', 'only 15.65', '1995', '60 miles', 'year', 'Sears) Tower', 'HALS', '44,103', 'Anish Kapoor', 'Academy of Nutrition and Dietetics', 'half', 'William Thompson', '2010, 2013, 2015', 'North Avenue', 'Gary/Chicago International Airport', 'the Museum Campus', 'British', '98.1%', '12 m', 'Washington', 'The University of Chicago', '1,045,560', 'The Chicago School of Professional Psychology', 'Tribune', 'West Town', 'Josephinum Academy', '1900', '1985', 'the Polish Museum of America', 'twenty-four', 'United Airlines', 'WBBM', 'more than 6,000', 'Adlai Stevenson', 'the Museum of Contemporary Art', 'Jean Baptiste Point du Sable', 'Central Park', 'Brass Era', 'Parliament', 'the Great Northern Migration (Saar', 'Harold Washington', '1833', 'Lithuanian', 'Ravinia Festival', 'May 4, 1886', '98', 'Harold Washington College', '2002', 'District of the Federal Reserve', 'Divvy', 'Brookfield', 'Ed Paschke', '205 m', 'Annual', '53', 'the Chicago Climate Exchange', '$1.95 billion', 'The Chicago Loop', 'the Town of Chicago', '5,800', 'Jesse Brown VA Hospital', '16th', 'Major League Baseball', 'Prison Break', 'St. Louis', '12', 'Illinois State Board of Health', '30', 'the Willis Tower', 'Grant Park', \"Moore's\", 'Jones College Prep', 'Kinzie Street Bridge', 'UIC', 'second', 'Jesuit', 'over 200', 'Rogers Park', 'Condé Nast Traveler', 'Catholic', 'July 2016', 'Indian', '1966', 'the Chicago Imagists', 'SouthtownStar', '1883', '1860', 'Northeastern Illinois University', 'HQ', 'WBBM 2', 'about 75%', 'Lincoln Park Zoo', '54,188', 'Seattle', 'Singapore', \"Frédéric Chopin's\", 'fourth', '1.308 million', 'the Latin School of Chicago', 'December 2016', 'Chicago Board of Health', 'Opera House', '47,408', 'DuSable Park', 'Richard Teller Crane', 'Carl Sandburg', 'Peace High School', 'Hyde Park', 'Olive–Harvey College', 'the mile', '1974', 'Crusader', 'fifty', 'the American', 'July daily', '62.8%', 'Ten years later', 'Enrico Fermi', '9.7 km', 'Loop', '1837', 'Bennett', 'ImprovOlympic', 'the Black Belt', '31', 'New York City', 'Historic Places', 'Polish', 'three', 'July', 'the early 1960s', 'Republicans', '45.0%', 'Daniel Burnham', '55 percent', 'Rohe', 'one', 'Still Standing, The League', 'the Goodman Theatre', '4,331', 'Rush University Medical Center', \"Richard J. Daley's\", 'PRI', 'Helmut Jahn', 'Midwestern', 'May 16, 2011', 'the White Sox', 'Civil War', '45', '1688', '750', '2,695,598', '468', 'Objectivist', '54 million', 'the University of Chicago Cultural Policy Center', 'six Stanley Cups', 'The University of Illinois College of Medicine', 'Cleveland', 'Thorvaldsen', 'Magnificent Mile', 'African American', 'CW', 'American Association of Nurse Anesthetists', 'Landing Lakefront Terminal', 'CPS', '109', 'approximately 153,000', 'early 1962', 'Richard M. Daley', '2,900 shootings—13%', 'the middle of the night and', 'Democrats', 'the Gangster Era', '1984', '42', 'the University of Illinois Medical Center at Chicago', 'Henri Joutel', '105', 'Copernicus', 'Horto', 'Ukraine', 'Hull House', 'the Saturday Night Live', 'Fortune Global 500 companies and 17', 'White House', 'the University of Chicago Crime Lab', 'each year', \"Wacław Szymanowski's\", 'the AT&T Plaza', 'Standing Beast', 'NYMEX', 'DuPage', 'Filipino', 'seventh', '1 mile', '580', 'Programs', 'Sears Tower', '600', 'Grant Park Music Festival', '1872', 'Trump International Hotel', 'Kenwood', 'Swedes', 'as many as 21 days', 'Roger Brown', 'Chicago Rockford International Airport', '61.7', '29.7%', 'Abbott Laboratories', 'The Illinois Department of Tourism', 'New Orleans', 'the ESPN Radio-owned', 'Cook', 'Salvadoran', 'Albert Raby', 'Bowman', 'Late in the 19th century', 'the School of the Art Institute of Chicago', 'four years', 'Presbyterian', 'The White Sox', 'Pontiac', 'Republican National Convention', 'Accreditation Council for Continuing Medical Education', 'early 1920s', 'Superfans', 'November', 'the Kansas City Southern Railway', 'the Field Museum of Natural History', 'Anton Cermak', 'Whitney M. Young', '19', 'Lawrence Avenue', 'Serbs', '0.2%', '97 km', '22nd Street', 'the University of Chicago', 'Cubs', 'over 3.6 million', 'U.S. Representatives', '2009', 'The Love Song of J. Alfred Prufrock', \"Anish Kapoor's\", 'D1', 'DuPage County', \"Frank Gehry's\", 'Guatemalan', '3,000', 'Barack Obama', 'Latino', 'Rush University', 'Topography', 'Walgreens', 'under 2.7 million', 'the National Register of Historic Places', 'Major League', 'East Wacker', 'Northside College Preparatory High School', 'Illinois', '1910', 'eight', '°', '0.4%', 'World Marathon Majors', 'the Calumet River', 'Chicagoland', 'Global Cities Index', 'The Port', 'Lollapalooza', 'weeks', '−33', '\\nNational Register of Historic Places', 'Czechs', 'Mies van der', '4', 'Newark', 'U.S. Department of Transportation', '1942', '1873', 'The A.V. Club', 'Southern', 'the Home Insurance Building', '16', '\\n\\n\\n', 'June 2017', '1950', 'White (', 'Ogden Avenue', '762', 'North America', 'Lakeview', '1803', \"Marshall Field's\", '2014–15', '196 ft', 'The Near West Side', 'Divergent', 'the Southern United States', 'Clark Street', 'recent years', 'Department of Transportation', 'the Jefferson Township', '1897', 'Near Eastern', 'St. Ignatius College Preparatory School', 'first', 'South Shore', 'American Community Survey', 'the Federal Reserve Bank of Chicago', '65', '35', 'Urbana', 'Robot, Mean Girls, Wanted', \"Fairbanks's\", 'The McLaughlin Group', 'Rate Field', 'William Butler Yeats', 'the Southwest Side', 'the United States Army', 'Visitor Information Center', 'Du Sable', 'Asian', 'Draugas', 'the Chicago Stock Exchange', 'Stan Mikita', 'Al Capone', '\\n', 'Preston Bradley Hall', 'Park District', 'The Chicago Bulls of', \"O'Hare Airport\", 'Lincoln', 'Chinese', 'Ecuadorian', 'Miami', 'Northwestern University', 'Constitution', '1917', 'Albanians', 'seven years', '29.3%', '10 feet', 'recent years – the Bears (', 'Race Riot', 'nearly 25,000', '1929', 'the Jay Pritzker Pavilion', 'the Feltre School in River North', 'South Bend', 'the Aon Center', '1934', 'the Prairie School', '431', 'North Side', 'about 130', '2014', 'US', 'Children, Kenan & Kel', 'Between 1910 and 1930', 'San Antonio', '\\n\\nChicago', 'the Windy City', 'Kościuszko', 'Greektown', 'Toyota Park', 'Advanced Placement', 'since 1992', 'the Illinois Institute of Art – Chicago', 'Chicago Dance Crash', '1975', 'the Near North Side', 'the Cook County Circuit Court', '7%', 'the Chicago Black Renaissance', 'Los Angeles', 'Richard J. Daley College', 'Northwestern Memorial Hospital', 'the Lutheran School of Theology at Chicago', 'Uptown', '125', 'the Chicago Freedom Movement', '2010', 'Solidarity Promenade', '0.6%', '1 million', 'the end of 2018', '92', 'Art Nouveau', 'Brioschi', 'the Museum of Science and Industry', 'Michigan Avenue', 'the New Negro Movement', 'Meigs Field', '1812', 'Köppen', '55th', '1.1%', 'Iroquois', 'the 1840s', 'Day Off', 'World Trade Center', 'night', 'the Eastern United States', 'Chicago High School for the Arts', 'Japanese', \"Dion O'Banion\", '28', \"Boyle's The Alarm\", 'sixty years', 'the winter season', 'the Chicago Region Environmental and Transport Efficiency', '2003', 'NBA', 'Peoples Gas', 'Law', 'Wrigley Field', 'The Chicago Board of Trade', 'the Windy City Times', 'the West Coast', 'The City Beautiful', 'about 300,000', 'Batcolumn', '19th century', 'Calumet', 'the \"Top Ten Cities', '5b', 'More than half', 'Millennium Park', 'the Chicago Mercantile Exchange', 'Armour and Company', 'The Blues Brothers', 'the dawn of the century', '1906', 'Robert de LaSalle', '29,000 square meters', 'Four Seasons', 'the Erikson Institute', 'Colombian', 'Amrany and Rotblatt-Amrany', '2019', 'Peoria', 'Chodzinski', 'February 23, 2011', 'The Chicago Police Department', 'Greyhound Lines', 'five', 'the Mississippi River', \"North America's\", 'the 1920s', 'Wisconsin', 'U.S.', '2008–2012', 'Germans', '71%', '22', 'First', 'ten', 'Illinois State', 'McCormick Place', 'Indianapolis', '578', 'Haymarket', '800,000 barrels', 'WGN America', '16.14', 'January', 'Little Vietnam', '1953-54', '2011', 'the Near South Side', 'ComEd', 'Indiana', 'The Chicago Blackhawks', 'Marc Chagall', 'CTA', 'Beauty and Crate & Barrel', '27.5 million', 'the National Weather Service', 'Manhattan Project', 'CBS', 'The Chicago Tribune', 'the spring', 'Alinea', \"the 'L'\", '3.6 million', 'Rosemont', 'only one', '1900 to 1939', 'the United States', 'American Osteopathic Association', 'LGBT', 'the American League', '25%', 'Honduran', 'Crunelle', 'Harlem', '0.40 km2', 'the Brookfield Zoo', 'Marshall Field', 'Chicago Union Railroad', 'the U.S. Department of Education', 'Oak Park', 'the forty years', 'eight seasons', 'the American Geographical Society Library\\nHistoric American Landscapes Survey', 'GRAB', 'Sufjan Stevens', '1795', 'This Great Migration', 'Labor', 'Ethnically', 'early 2018', 'Jaume Plensa', 'U.S. Presidents (Eisenhower', 'the Chicago Teachers Union', 'the Art Institute of Chicago', 'the Chicago Loop', '94', 'NPR', 'Chicagoua', 'Combo', '25 miles', 'the Lyric Opera', 'the Buehler Center', 'World', 'Polasek', 'Bulls', 'NFL', 'WNBA', '176.5 m', 'the University of Chicago Laboratory Schools', \"Ann & Robert H. Lurie Children's\", 'Newcity', 'National Blue Ribbon School', 'between 2010 and 2040', '20th', 'one quarter', 'Pakistani', 'Boeing', 'Portland', '448', 'National Louis University', 'the Great Lakes Megalopolis', '52', 'Elston', 'Moose', 'ULTA', 'the Near West Side', 'CSO', '860-880 Lake Shore Drive Apartments', 'four', 'the Battle of Fort Dearborn', 'Dziennik Związkowy', 'the Crown Fountain', 'Little Calumet River', 'the North Side', '31.7%', 'the summer', \"Bill Swerski's\", 'Quincy', 'Imagist', 'U of C', 'the Harris Theater', 'Lake Michigan', '200', 'the Driehaus Museum', 'American College of Healthcare Executives', 'New York', 'the Wabash Avenue Bridge', 'the Illinois and Michigan Canal', 'two-thirds', '2010–11', 'Peruvian', '100,000', '506', 'Douglas', 'Justice', \"Northern Indiana Commuter Transportation District's\", 'the Midway Plaisance', 'The Illinois Medical District', 'Picasso', 'the Schwinn Bicycle Company', '42 km', 'Jane Byrne', 'the John Hancock Center', 'over 4,000', 'Allium', \"the World's Religions\", '1885', 'nearly 150 percent', 'Lincoln Park', '57', 'the 2006 WNBA season', '390', 'Ace Hardware', 'the Chicago Sun-Times', '1926', 'Amrany', 'Joliet Junior College', '1912', 'the Pritzker Military Library', '22.1%', 'the Green Bay Packers', 'Hospital of Chicago', 'This American Life', '1924', 'Standing Lincoln', '29%', 'Landmarks', 'The Chicago Transit Authority', 'During World War', 'Chi-Town', 'about 4.48 million', 'Glencoe', 'the Chicago Building', 'year 2014', 'Port Huron', 'Leon Golub', 'Meštrović', 'the 19th century', 'February 1856', 'Ojibwe', 'State Street', 'DW60', 'Richard J. Daley', 'the 20th century', 'the Chicago Literary Renaissance', 'the Rehabilitation Institute of Chicago', 'the Federal ATF', 'over 8,000 acres', 'Potawatomi', '75', 'Blue Island', 'the Art Institute of Chicago, Museum Campus', 'the MasterCard Worldwide Centers of Commerce', 'CBS Radio', '13.2', 'Puerto Rican', 'more than 77%', 'between 1920 and 1930', 'D.C.', 'Christopher Columbus', 'the Catholic Theological Union', '1901', 'the 1870s and 1880s', 'The Willis Tower', 'the Democratic Party', 'The City Council', 'Galena', '8,390,000 square feet', 'Merc', '3,200', 'Derrick Rose', '2015', 'Christians', '2012', 'the mid-18th century', 'Malcolm X College', \"New York's\", 'Metra Electric Line', '1994', 'the 1990s', 'Black Belt', 'Healthcare', 'Jack Brickhouse', 'fifth', 'Frédéric Chopin', 'WLS', 'Chagall', 'the Arizona Cardinals', 'MLB', 'the Hyde Park Township', 'Art Institute of Chicago', 'Batman', 'Michelin Guide', '2.5', 'more than US$13.7 billion', 'M.D', 'South Side', 'North Chicago', 'DMOZ', 'De La Salle Institute', 'Pizzeria Uno', 'American College of Surgeons', 'Navy Pier', 'Albany Park', 'The Second City', 'September 9, 2013', '50.17 million', 'the Garfield Park Conservatory', 'John Crerar', 'Egyptian', '3,000 linear feet', 'December 20, 2014', \"O'Hare International Airport\", 'CBOE', 'Jefferson Park', 'LaPorte', 'about 200', 'between 1910 and 1920', 'Gateway Theatre', '1869', 'the Tribune Media', 'the New York Mercantile Exchange', '32', '3', 'July 24, 1934', 'Democratic Party', 'State', 'South Halsted Street', '28.9%', 'the U.S. Futures Exchange', 'the National Mall', 'Illinoisan', 'Site Selection', 'Ford Motor Company', 'the Port of Chicago', 'the Great Lakes south', 'Claire', '294', 'September 10, 2012', 'U.S. Census', '579', 'the Chicago Opera Theater', '\\n\\nSporting News', 'Chicagoans', 'Cook County Forest', '201 meters', 'Lincoln Park Conservatory', 'thousands', '250 million US gallons', '44th', 'The American Medical Association, Accreditation Council', 'Chicagou', 'early summer', 'the Chicago School', 'North Park University', 'Truman College', 'French', 'nearly 400 acres', 'Millions', 'the \"Original Six\"', '190', '1955', '1874', 'Louis Sullivan', 'Yellow', 'the Chicago Public Schools', '9', 'the twentieth century', 'Vesuvio', 'Bruce DuMont', 'the Adler School of Professional Psychology', 'RTA', \"Ferris Bueller's\", '100 acres', 'the Red, Blue', 'Joseph Jefferson Awards', 'Seven', 'University of Illinois at Chicago', 'Michigan Canal', \"the Illinois State's\", 'every day of the year', 'Little Seoul', '1977', '40 km', 'John Paul II', 'nineteen', 'Today', 'late September 1687:', 'Bridgeview', 'Stritch School of Medicine', 'American Literature', 'Robert Morris University Illinois', \"O'Hare Airports\", 'the summer of 2016', 'Lady Michelle Obama', 'Shimer College', 'Cadillac Palace Theatre', 'Molly', '1860s', 'Paseo Boricua', '3.8%', '2.7%', 'the Chicago Pride Parade', 'winter', 'the Lycée Français de Chicago', 'Boston', 'the Feinberg School of Medicine', 'Burnham', 'the Treaty of Chicago', 'Illinois Congressman', '1907', 'Columbian Exposition', 'Illinois Institute of Technology', 'American', 'the Morgan Park Academy', 'June 15, 1835', 'more than 4,000', 'John Whitfield Bunn', 'Republican', 'the Evangelical Lutheran Church in America', 'Northwest Side', 'the Society for Human Rights', 'the Illinois International Port District', 'Crown Fountain', 'the Chicago State Cougars (', 'fewer than 200', 'more than 570', '2013', 'John Farwell', 'The Chicago Marathon', 'the Feinberg School of Medicine of Northwestern University', '1979', 'Jews', 'Italians', '3 km', 'Bill Savage', 'Chase Tower', '2005–2009', '4.0', '233,903', 'St. Rita of Cascia High School', 'its first hundred years', 'Prohibition', 'Parks', 'West Side', 'the latter half of the 20th century', 'Cuban', 'the American Hospital Association and Blue Cross', 'The Good Wife', '50', '18th', 'Gwendolyn Brooks', 'Midwest', 'June 4, 1998', 'Europe', 'the Plan of Chicago', 'Caterpillar Inc.', 'the Allstate Arena', 'Blackhawks', 'the Northern District', 'Ezra Pound', '1970', 'McDonald', '500', 'Exelon', '16 percent', 'two', 'the National Basketball Association', 'U.S. News & World Report', 'the last half of the 19th century', 'Ottawa', 'Harpo Studios', 'Midway International Airport', 'Sunday', 'Iowa', 'the Chicago Board of Trade', 'Spearman', 'The City of Chicago', 'the Port District', 'Metaxa', '1679', 'Sixteen Candles', 'Chicago Public Radio', 'The River North Gallery District', 'the Daily Herald', 'Sister', 'Rick Bayless', '400,545', 'two miles', 'six', 'WGN-TV', 'Lake', '1968', 'Franklin D. Roosevelt', 'Lorado Taft', 'Warsaw', '5%', 'Miami-Illinois', 'the following decades', 'Fox', 'Western Avenue', 'The 2015 year-end', '0.3%', '32.9%', '1989', 'FIFA World Cup', 'about one', '1.72 million', 'Buckingham', 'Michael Jordan', 'Picnic', 'UBS', '22%', 'the Tribune Broadcasting-owned', 'Kennedy', '43', 'the 1910s', 'Indians', 'Magdalena Abakanowicz', '11.09 million', 'Academy of General Dentistry', \"Loyola University Chicago's\", 'Washington Park', 'Robert Lostutter', 'Abraham Lincoln', 'the Sears Tower', '\\n\\nRenowned Chicago', 'roughly 60%', 'Devon Avenue', '30,000', '55.7', '910 m', 'Walk Score', 'Megabus', 'St. Patrick High School and Resurrection High School', 'African Americans', '1:1‑scale', 'Lake, McHenry, DuPage', 'Kearney', 'the Red and Blue', 'recent 2015', 'about 1900', 'Sox', 'the 2008–2012 American Community Survey', 'Rochester', 'Rick Tramonto', 'Central and Eastern Europe', 'The Dark Knight', 'the Flag of Chicago', 'African-Americans', 'Roosevelt University', 'United States', '24 hours', '8', 'Armour Square', '0.1%', '458', 'La Villita', 'The Chicago Lincoln', 'Obama', 'Maywood', 'Kraft Heinz', '55', 'Signal of Peace', \"T. S. Eliot's\", 'Fortune 1000', 'June', 'Discovery', 'Common Council', '9th', '6th', 'the Logan Square Boulevards Historic District', 'PBS', 'Six', 'NFL Championships', 'the year before', 'the DuSable Museum of African American History', 'the 1920s and 1930s', 'Batman Begins', 'Poetry.', 'Union Station', 'Soldier Field', 'Montenegrins', 'several consecutive days', '38.9', '88', 'P.D.', '355', '77', 'Frank Lloyd Wright', 'the Chicago Tribune', 'January 20, 1985', 'Cityscape', 'the Great Chicago Fire', 'Ivan Albright', 'Bobby Hull', 'Two years later', 'South', '18.5', 'The University of Chicago Oriental Institute', 'Pace', 'John H. Rauch', 'five 50,000 watt', 'the Western Hemisphere', '1905', '2.7 million', 'Mike', 'USDA', '1,000,000', '34', 'Robb Report', 'Electronic Dance Music', 'Illinois International Port', 'the Obama Foundation', 'seven', 'today', 'African', 'William Rainey Harper', '315,000 square feet', 'Italian', 'Andersonville', 'the year', 'Thanksgiving', 'nine', 'Punky Brewster', 'Maps of Chicago', 'William Carlos Williams', 'several decades', 'Martin Luther King Jr.', 'Wilbur Wright College', 'Horizon League', 'Chicago State University', \"Lions, Saint-Gaudens's Abraham Lincoln\", 'Orbitz', 'Seventh', '59%', 'about 29', 'Alderman Eugene Sawyer', 'the 2010–11 season', 'Poles', 'Edmund Dick Taylor', '1927', 'Cristo Rey Jesuit High School', 'Saturday, March 4, 1837', 'DePaul College Prep', 'the Chicago Cubs', 'the Chicago Portage', '\\nList of fiction', 'Water Tower Place', 'the South Side of Chicago', 'the year 2016', 'several square miles', '32.6%', 'Kennedy–King College', 'Hindus', '21st', 'CME Group', '6 miles', 'the University of Chicago Divinity School', 'the Chicago Board of Trade Building', 'Chicago', 'a World Series', 'the Chicago White Sox', 'close to five years', 'the Peggy Notebaert Nature Museum', 'IL', 'Stephen Douglas', 'the Chicago Shakespeare Theater', 'the Treaty of Greenville', 'Civic', 'first eight seasons', 'the Chicago Police Department', 'eleven', 'the John Marshall Law School', '13', '60 m', 'About 18.3%', 'Broadway', \"Oprah Winfrey's\", 'the Barack Obama Presidential Center', 'Jackson Parks', 'Willis Tower', '1983', 'Chicago Hope', '\\n\\nChicago Wilderness\\nGentrification of Chicago', 'Bronzeville', 'Sneak Previews'}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1537\n"
     ]
    }
   ],
   "source": [
    "chicago_model = nlp(chicago.content)\n",
    "named_entities = []\n",
    "for entity in chicago_model.ents:\n",
    "    named_entities.append(entity.text)\n",
    "print(set(named_entities), len(set(named_entities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Understanding 2 (10 Minutes)\n",
    "\n",
    "As a market (or as groups in your market), please discuss the following:\n",
    "\n",
    "1. As modelers, we will frequently have to make decisions about how to transform data. If you were using NLP to predict things, would it make sense to keep named entities? Would it make sense to drop them? If it would depend on the circumstances, under what circumstances would it make sense to keep or drop named entities?\n",
    "\n",
    "We'll have a couple of markets come on mic to discuss cases they identified where keeping named entities might make sense and cases where it would not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `textblob` to do sentiment analysis\n",
    "\n",
    "We can also use a library known as [`textblob`](https://textblob.readthedocs.io/en/dev/) to do a **lot** of text transformation and extraction on our behalf. For our purposes, we are going to use it to analyze text and derive the overall sentiment of the text.\n",
    "\n",
    "Sentiment can be split into two related scales:\n",
    "\n",
    "- subjectivity (0 to 1): scores closer to 0 are more objective in tone, scores closer to 1 are more subjective in tone\n",
    "- polarity (-1 to 1): scores closer to -1 are more negative in tone, closer to 0 are more neutral, and closer to 1 are more positive in tone.\n",
    "\n",
    "Using `textblob` is user-friendly -- pass a string into a `Textblob()` class and then call the `.sentiment.polarity` or `sentiment.subjectivity` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_good_review = '''\n",
    "Goodness me, what a fantastic movie. \n",
    "Caught the world premiere at the Toronto International Film Festival and \n",
    "the entire theater laughed until they cried. \n",
    "Amazingly directed, HILARIOUSLY funny, it blends a 1930s gangster \n",
    "stylishness into a Hong Kong kung fu movie to astonishing results. \n",
    "Who would've thought you could top Shaolin Soccer? \n",
    "Not me, until I saw this movie. Stephen Chow pulled it off. \n",
    "Chow's comedic timing gets better and better with every movie \n",
    "he makes, and while his films are depending more and more on \n",
    "CGI these days, and makes this movie much more a fantasy kung \n",
    "fu film than a traditional one, it hardly detracts from the \n",
    "enjoyable experience. Make it your mission to see this film - \n",
    "it will be one of the most entertaining you ever see. \n",
    "I can't remember the last film I enjoyed myself in more. \n",
    "My eyes still hurt from wiping away tears of laughter. Seriously.  \n",
    "'''\n",
    "\n",
    "really_bad_review = '''\n",
    "Thank you for coming into your performance review Mr. Smith.\n",
    "The company is concerned about your performance. Lately your work has \n",
    "been subpar and at times counter to this company's stated goals.\n",
    "Your demeanor has been aggresive and at times hostile to your \n",
    "fellow coworkers.\n",
    "We have no choice but to terminate your employment, effective \n",
    "immediately. Thank you.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5749999999999998 0.33295454545454545\n",
      "0.7 0.15\n"
     ]
    }
   ],
   "source": [
    "good_review = TextBlob(really_good_review)\n",
    "print(good_review.sentiment.subjectivity, good_review.sentiment.polarity)\n",
    "\n",
    "bad_review = TextBlob(really_bad_review)\n",
    "print(bad_review.sentiment.subjectivity, bad_review.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Understanding 3 (5 Minutes)\n",
    "\n",
    "Individually, please answer the following:\n",
    "\n",
    "1. What type of subjectivity and polarity scores would you expect wikipedia articles to have?\n",
    "2. Confirm your hypothesis by using `textblob` on some of the wikipedia pages we have used so far. Were your thoughts confirmed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamprey = wikipedia.page('lamprey')\n",
    "lamprey_textblob = TextBlob(lamprey.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjectivity score: 0.42203660749730604\n",
      "polarity score: 0.07442584925991039\n"
     ]
    }
   ],
   "source": [
    "print('subjectivity score:', lamprey_textblob.sentiment.subjectivity)\n",
    "print('polarity score:', lamprey_textblob.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42203660749730604 0.07442584925991039\n"
     ]
    }
   ],
   "source": [
    "good_lamprey = TextBlob(lamprey.content)\n",
    "print(good_lamprey.sentiment.subjectivity, good_lamprey.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding these features to DataFrames\n",
    "\n",
    "We may want to include these features into a DataFrame for use in a later model. The most straightforward way to do so would be to apply them using Pandas.\n",
    "\n",
    "Here, we'll make use of the same dataset on economic news that we used yesterday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>The Wall Street Journal OnlineThe Morning Brie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance                                           headline  \\\n",
       "0          1              Yields on CDs Fell in the Latest Week   \n",
       "1          0  The Morning Brief: White House Seeks to Limit ...   \n",
       "2          0  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3          0  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4          1  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "                                                text  \n",
       "0  NEW YORK -- Yields on most certificates of dep...  \n",
       "1  The Wall Street Journal OnlineThe Morning Brie...  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...  \n",
       "3  The statistics on the enormous costs of employ...  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ = pd.read_csv('datasets/economic_news.csv',\n",
    "                  usecols=[7, 11, 14],\n",
    "                  nrows=200)\n",
    "econ['text'] = econ['text'].apply(lambda x: x.replace('</br>', ''))\n",
    "econ['relevance'] = econ['relevance'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(econ[['text']],\n",
    "                                                   econ['relevance'],\n",
    "                                                   test_size=0.50,\n",
    "                                                   random_state=8675309)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `spaCy` to create a column for the number of monetary-based named entities, followed by using `textblob` to create a polarity score for each article.\n",
    "\n",
    "While we can try to put this into a lambda function, it will probably be easiest in this case to define four functions and apply them.\n",
    "\n",
    "However, because we're sequentially loading up each row of data and processing it, this can be a little bit of a time and memory sink. Expect processing to take some extra time for this step.*\n",
    "\n",
    "* **note**: for spacy, there are faster ways to process the data that do not involve pushing it through Pandas. Investigate the spacy `pipe` method if you're looking to do a larger amount of text transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_monetary_ents(text):\n",
    "    text = nlp(text)\n",
    "    return len([x.text for x in text.ents if x.label_ == 'MONEY'])\n",
    "\n",
    "def polarity(text):\n",
    "    text = TextBlob(text)\n",
    "    return text.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['num_monetary'] = X_train['text'].apply(number_of_monetary_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       1.420000\n",
       "std        2.123367\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        2.000000\n",
       "max        8.000000\n",
       "Name: num_monetary, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['num_monetary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c380b57cf8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkKTGWQSS1DiLQJIaZxFIUuP+D+/+Wh78Lue2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c380d82f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train['num_monetary'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['polarity'] = X_train['text'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c380b4da90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnEUgSY2zCCSpcf8DN9U4zbDaiZQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3f2d596d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train['polarity'].describe()\n",
    "X_train['polarity'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also pass this into a predictive model to see if these features can assist predicting economic status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "[[79  0]\n",
      " [ 5 16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        79\n",
      "          1       1.00      0.76      0.86        21\n",
      "\n",
      "avg / total       0.95      0.95      0.95       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train[['num_monetary', 'polarity']], y_train)\n",
    "print(rfc.score(X_train[['num_monetary', 'polarity']], y_train))\n",
    "predictions = rfc.predict(X_train[['num_monetary', 'polarity']])\n",
    "print(confusion_matrix(y_train, predictions))\n",
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "[[61  6]\n",
      " [30  3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.91      0.77        67\n",
      "          1       0.33      0.09      0.14        33\n",
      "\n",
      "avg / total       0.56      0.64      0.56       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test['num_monetary'] = X_test['text'].apply(number_of_monetary_ents)\n",
    "X_test['polarity'] = X_test['text'].apply(polarity)\n",
    "print(rfc.score(X_test[['num_monetary', 'polarity']], y_test))\n",
    "predictions = rfc.predict(X_test[['num_monetary', 'polarity']])\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: you're probably wondering _why_ we would try these things when they don't seem to immediately help. During a larger project, we will likely spend days if not weeks on feature extraction and analysis and will want to make as many useful features as possible to make as good a model as possible. Other techniques may involve more nuanced modeling, such as looking at the sequence of parts of speech, etc. Part of this lesson is designed to expose to what is out there so that when faced with a situation where those techniques may be useful, you're aware of their existence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning documents to topics using LDA\n",
    "\n",
    "LDA (Latent Dirichlet Allocation) is an unstructured machine learning technique that iteratively attempts to find clusters of words that are likely to happen together across multiple documents. We interpret the co-occurance of these words together to be analgous to different topics discussed in across a body of documents. \n",
    "\n",
    "LDA works by iteratively guessing how likely a given word is to be part of a given topic until we tell it to stop. \n",
    "\n",
    "This process of updating probabilities will make more sense after next weeks lectures on Bayes, but we'll quickly discuss here and move forward.\n",
    "\n",
    "(Explanation cribbed from [Introduction to Latent Dirichlet Allocation](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/))\n",
    "\n",
    "We begin by picking a set of documents and a number of topics that we want to generate. One way that we do this is what's known as collapsed Gibbs saampling. We do the following:\n",
    "\n",
    "1. Randomly assign every word in every document to one of the $k$ topics:\n",
    "    - $w$: a word in a document\n",
    "    - $d$: a document\n",
    "    - $k$: a topic\n",
    "2. At this point, every word has a likelihood that they belong in a given a topic, based on the other words in documents that they exist in. \n",
    "3. Iterate through every word in every document and:\n",
    "    1. Assume that every other word has the correct likelihood that they belong to each topic (so, `apple` might have a distribution of `[0.1, 0.1, 0.2, 0.4, 0.2]` for five topics.\n",
    "    2. Look at the likelihood of seeing word $w$ in document $d$ and adjust the topic probabilities as needed\n",
    "    > for example, if there are a lot of words in topic 1 in document $d$ and word $w$ has a stronger likelihood of being in topic 2, because we're assuming that every **other** distribution is correct, we should change our understanding of where word $w$ belongs and tweak it more in favor of belonging to topic 1, not topic 2\n",
    "    \n",
    "You can kind of interpret this with an analogy:\n",
    "\n",
    "> Imagine you move to a new town and you don't know what sort of people you want to hang out with. You imagine there's five different groups of people. You start visiting different places around town (the park, the library, the mall, etc.) and noting who's there. Everytime you go to a place you start adjusting your expectation on who you'll see there (such as the goths constantly are at the mall, so we should expect less and less that they'll show up at the library). This is (very roughly) analgous to what LDA is doing.\n",
    "\n",
    "The name latent dirichlet allocation should begin to make more sense in this context:\n",
    "- latent -- because we have no explicit marker of topic and are grouping things together based on features we are inferring, not seeing\n",
    "- [dirichlet](https://en.wikipedia.org/wiki/Dirichlet_distribution) -- is a type of probability distribution for multiple vectors at once (like a bunch of words towards a bunch of topics)\n",
    "- allocation -- we are allocating different words to different topics via this iterative updating of priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sklearn and `gensim`, a library we will discuss in the context of a technique called `word2vec`, can handle LDA. However, we'll rely on the sklearn implementation here to reduce the amount of extra work we'll need to do in picking up a new library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's reimport all of the economic news data instead of just the first 200 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Wall Street Journal OnlineThe Morning Brie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  NEW YORK -- Yields on most certificates of dep...\n",
       "1  The Wall Street Journal OnlineThe Morning Brie...\n",
       "2  WASHINGTON -- In an effort to achieve banking ...\n",
       "3  The statistics on the enormous costs of employ...\n",
       "4  NEW YORK -- Indecision marked the dollar's ton..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ = pd.read_csv('datasets/economic_news.csv',\n",
    "                  usecols=[14])\n",
    "econ['text'] = econ['text'].apply(lambda x: x.replace('</br>', ''))\n",
    "econ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll transform the data using `CountVectorizer` and removing stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x46379 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 802395 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(econ['text'].values)\n",
    "X = cv.transform(econ['text'].values)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll instantiate an LDA and fit it to our sparse matrix of words. We have to provide a number of topics that we are looking for (in this case, we're looking for 5 topics). We'll also store the names of the each of the words created during the `CountVectorizer` step for use with the LDA results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1, n_topics=5,\n",
       "             perp_tol=0.1, random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "lda = LatentDirichletAllocation(n_topics=5)\n",
    "\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our work will be held in the `.components_` feature. Each row of this array is one of our topics and each column (in order) is a word created by `CountVectorizer`. The values are the relative \"likelihoods\" that the word $w$ should be in topic $t$.\n",
    "\n",
    "> From the sklearn docs, `.components_`: \"can be viewed as pseudocount that represents the number of times word j was assigned to topic i. It can also be viewed as distribution over the words for each topic after normalization\" (we could normalize by dividing row total for that topic). \n",
    "\n",
    "For our purposes, it's enough to say that bigger values means the word belongs more in that topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 46379)\n"
     ]
    }
   ],
   "source": [
    "print(lda.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(lda.components_,\n",
    "                      columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what words are most likely in each topic, we could sort by the biggest values for each topic.\n",
    "\n",
    "> Every feature has a likelihood of being in a topic, just a very, very low one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "said million company year companies new stock billion industry 000 corp bank market business banks share securities percent loans home mortgage sales according credit based \n",
      "\n",
      "Topic 1\n",
      "trade japan world china japanese countries united europe foreign european nations germany global international german currency west chinese tokyo american asia minister asian london south \n",
      "\n",
      "Topic 2\n",
      "market year said stock rates new percent rate prices economy stocks average york investors inflation economic index growth week dollar rose fed dow federal points \n",
      "\n",
      "Topic 3\n",
      "ыєs ыќ cent ыє ыєt ыу ыў ыуthe ыпthe рк ыпwe press ыпi ыуand rails ыєre today ыч ыпit ыќthe 10 ыпa col ing eisenhower \n",
      "\n",
      "Topic 4\n",
      "said president federal tax economic government budget year years house new administration mr people state economy money congress deficit time spending chairman unemployment inflation states \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(5):\n",
    "    print('Topic', topic)\n",
    "    word_list = results.T[topic].sort_values(ascending=False).index\n",
    "    print(' '.join(word_list[0:25]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we change the number of topics, we should see the topics change slightly. Remember that because this is an unstructured technique our editorial power as the modeler is important to identify useful topics. \n",
    "\n",
    "However, this provides a powerful tool to create summaries of larger bodies of documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Understanding 4 (20 Minutes)\n",
    "\n",
    "In pairs, do the following:\n",
    "\n",
    "1. Rerun the LDA, choosing 10 topics instead of 5. \n",
    "> Make sure that you can explain what each line of the code does to each other. This can be as generic as \"This runs an LDA with 10 components on a matrix of words and documents\" but it's important to be able to explain what a block of code is doing. In particular, make sure that you're able to explain what has happened in this line of code above `word_list = results.T[topic].sort_values(ascending=False).index` -- if you need to, start with the very first portion (`results`) and investigate what each subsequent step does.\n",
    "2. Look at the results of your LDA. How would you summarize what each topic says?\n",
    "3. Does 10 look to be a correct number of topics? Are the same words showing up in multiple topics? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1, n_topics=10,\n",
       "             perp_tol=0.1, random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "lda = LatentDirichletAllocation(n_topics=10)\n",
    "\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(lda.components_,\n",
    "                      columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "company million said county year corp business sales percent share based years like area executive 000 companies stores home people ford time district revenue says \n",
      "\n",
      "Topic 1\n",
      "stock market new stocks york average dow points trading million index shares investors jones day week said industrial today rose prices fell year exchange 30 \n",
      "\n",
      "Topic 2\n",
      "dollar yen gold currency york new euro futures trading ap late traders exchange currencies marks foreign press japanese goldman court ounce commodity pound metals yesterday \n",
      "\n",
      "Topic 3\n",
      "said new people workers work state federal 000 pay years million time national business jobs year american bank unemployment government loan job cost industry board \n",
      "\n",
      "Topic 4\n",
      "billion market year rates money markets financial trade bank funds investors world fund said debt investment banks companies treasury mortgage years japan securities new bonds \n",
      "\n",
      "Topic 5\n",
      "col martin ыє brimmer ыў lias ез lockheed 1953 ii mil hr tires tables coach arab northrop machine pf inherited dressed nasa harold ol att \n",
      "\n",
      "Topic 6\n",
      "airlines airline air lo du ыуis airport pont airways ыў ыуas river scattered fares allied ы_ corrections amr southwest flights tion fare bag breast roaring \n",
      "\n",
      "Topic 7\n",
      "percent year said rate economy inflation economic rates prices fed growth federal reserve month increase recession consumer quarter department yesterday price months report sales new \n",
      "\n",
      "Topic 8\n",
      "ыєs ыќ ыє ыєt ыу ыў carter ыпthe рк ыуthe ыпwe ыуand ыєre steels ыч ыпit ыќthe ыпa ыуwhich employes ыєve ыуbut art ыпin ыпthere \n",
      "\n",
      "Topic 9\n",
      "president tax budget house said administration congress federal mr bush deficit chairman government senate white committee spending political economic taxes billion reagan clinton fiscal yesterday \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(10):\n",
    "    print('Topic', topic)\n",
    "    word_list = results.T[topic].sort_values(ascending=False).index\n",
    "    print(' '.join(word_list[0:25]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
